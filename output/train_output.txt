
=============
== PyTorch ==
=============

NVIDIA Release 24.07 (build 100464919)
PyTorch Version 2.4.0a0+3bcc3cd
Container image Copyright (c) 2024, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Copyright (c) 2014-2024 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com
Obtaining file:///workspace/simpleRL-swebench/train
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Checking if build backend supports build_editable: started
  Checking if build backend supports build_editable: finished with status 'done'
  Getting requirements to build editable: started
  Getting requirements to build editable: finished with status 'done'
  Preparing editable metadata (pyproject.toml): started
  Preparing editable metadata (pyproject.toml): finished with status 'done'
Collecting accelerate (from openrlhf==0.5.0)
  Downloading accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)
Collecting bitsandbytes (from openrlhf==0.5.0)
  Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)
Collecting datasets (from openrlhf==0.5.0)
  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)
Collecting deepspeed==0.15.0 (from openrlhf==0.5.0)
  Downloading deepspeed-0.15.0.tar.gz (1.4 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.4/1.4 MB 27.1 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from openrlhf==0.5.0) (0.8.0)
Collecting flash-attn==2.6.1 (from openrlhf==0.5.0)
  Downloading flash_attn-2.6.1.tar.gz (2.6 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.6/2.6 MB 29.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting isort (from openrlhf==0.5.0)
  Downloading isort-6.0.0-py3-none-any.whl.metadata (11 kB)
Collecting jsonlines (from openrlhf==0.5.0)
  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)
Collecting loralib (from openrlhf==0.5.0)
  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)
Collecting optimum (from openrlhf==0.5.0)
  Downloading optimum-1.24.0-py3-none-any.whl.metadata (21 kB)
Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from openrlhf==0.5.0) (24.0)
Collecting peft (from openrlhf==0.5.0)
  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)
Collecting ray==2.12.0 (from ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading ray-2.12.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)
Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from openrlhf==0.5.0) (2.9.0)
Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openrlhf==0.5.0) (2.4.0a0+3bcc3cddb5.nv24.7)
Collecting torchmetrics (from openrlhf==0.5.0)
  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)
Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openrlhf==0.5.0) (4.66.4)
Collecting transformers==4.46.1 (from openrlhf==0.5.0)
  Downloading transformers-4.46.1-py3-none-any.whl.metadata (44 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 44.1/44.1 kB 69.1 MB/s eta 0:00:00
Collecting transformers_stream_generator (from openrlhf==0.5.0)
  Downloading transformers-stream-generator-0.0.5.tar.gz (13 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting wandb (from openrlhf==0.5.0)
  Downloading wandb-0.19.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)
Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from openrlhf==0.5.0) (0.43.0)
Collecting word2number (from openrlhf==0.5.0)
  Downloading word2number-1.1.zip (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting zss (from openrlhf==0.5.0)
  Downloading zss-1.2.0.tar.gz (9.8 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting hjson (from deepspeed==0.15.0->openrlhf==0.5.0)
  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)
Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.15.0->openrlhf==0.5.0) (1.11.1.1)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.15.0->openrlhf==0.5.0) (1.24.4)
Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.15.0->openrlhf==0.5.0) (5.9.8)
Collecting py-cpuinfo (from deepspeed==0.15.0->openrlhf==0.5.0)
  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)
Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.15.0->openrlhf==0.5.0) (2.8.2)
Collecting nvidia-ml-py (from deepspeed==0.15.0->openrlhf==0.5.0)
  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)
Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (8.1.7)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (3.15.4)
Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (4.23.0)
Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (1.0.8)
Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (4.24.4)
Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (6.0.1)
Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (1.3.1)
Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (1.4.1)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (2.32.3)
Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[default]==2.12.0->openrlhf==0.5.0) (3.9.5)
Collecting aiohttp-cors (from ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)
Collecting colorful (from ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)
Collecting py-spy>=0.2.0 (from ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)
Collecting opencensus (from ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)
Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default]==2.12.0->openrlhf==0.5.0) (0.20.0)
Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default]==2.12.0->openrlhf==0.5.0) (7.0.4)
Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading virtualenv-20.29.2-py3-none-any.whl.metadata (4.5 kB)
Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]==2.12.0->openrlhf==0.5.0) (1.62.1)
Collecting memray (from ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading memray-1.15.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (19 kB)
Collecting huggingface-hub<1.0,>=0.23.2 (from transformers==4.46.1->openrlhf==0.5.0)
  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.1->openrlhf==0.5.0) (2024.5.15)
Collecting safetensors>=0.4.1 (from transformers==4.46.1->openrlhf==0.5.0)
  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)
Collecting tokenizers<0.21,>=0.20 (from transformers==4.46.1->openrlhf==0.5.0)
  Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)
Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openrlhf==0.5.0) (4.12.0)
Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openrlhf==0.5.0) (1.13.0)
Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openrlhf==0.5.0) (3.3)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openrlhf==0.5.0) (3.1.4)
Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openrlhf==0.5.0) (2024.5.0)
Collecting pyarrow>=15.0.0 (from datasets->openrlhf==0.5.0)
  Downloading pyarrow-19.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)
Collecting dill<0.3.9,>=0.3.0 (from datasets->openrlhf==0.5.0)
  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)
Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->openrlhf==0.5.0) (2.2.1)
Collecting xxhash (from datasets->openrlhf==0.5.0)
  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)
Collecting multiprocess<0.70.17 (from datasets->openrlhf==0.5.0)
  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)
Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->openrlhf==0.5.0) (23.2.0)
Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openrlhf==0.5.0) (2.1.0)
Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openrlhf==0.5.0) (2.32.0)
Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openrlhf==0.5.0) (0.4.6)
Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openrlhf==0.5.0) (3.6)
Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openrlhf==0.5.0) (68.2.2)
Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openrlhf==0.5.0) (0.6.1)
Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openrlhf==0.5.0) (1.8.1)
Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openrlhf==0.5.0) (3.0.3)
Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages/lightning_utilities-0.11.3.post0-py3.10.egg (from torchmetrics->openrlhf==0.5.0) (0.11.3.post0)
Collecting docker-pycreds>=0.4.0 (from wandb->openrlhf==0.5.0)
  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)
Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->openrlhf==0.5.0)
  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)
Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->openrlhf==0.5.0) (4.2.2)
Collecting sentry-sdk>=2.0.0 (from wandb->openrlhf==0.5.0)
  Downloading sentry_sdk-2.20.0-py2.py3-none-any.whl.metadata (10 kB)
Collecting setproctitle (from wandb->openrlhf==0.5.0)
  Downloading setproctitle-1.3.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)
Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from zss->openrlhf==0.5.0) (1.16.0)
Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]==2.12.0->openrlhf==0.5.0) (6.0.5)
Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]==2.12.0->openrlhf==0.5.0) (1.9.4)
Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]==2.12.0->openrlhf==0.5.0) (4.0.3)
Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->openrlhf==0.5.0)
  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->openrlhf==0.5.0) (5.3.3)
Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->openrlhf==0.5.0) (0.4.0)
Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->openrlhf==0.5.0) (4.9)
Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->openrlhf==0.5.0) (2.0.0)
Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->deepspeed==0.15.0->openrlhf==0.5.0) (0.7.0)
Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->deepspeed==0.15.0->openrlhf==0.5.0) (2.20.1)
Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (3.7)
Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (2.0.7)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (2024.7.4)
Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)
Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->openrlhf==0.5.0) (2.1.5)
Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (2023.12.1)
Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (0.35.1)
Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (0.19.0)
Requirement already satisfied: rich>=11.2.0 in /usr/local/lib/python3.10/dist-packages (from memray->ray[default]==2.12.0->openrlhf==0.5.0) (13.7.1)
Collecting textual>=0.41.0 (from memray->ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading textual-1.0.0-py3-none-any.whl.metadata (9.0 kB)
Collecting opencensus-context>=0.1.3 (from opencensus->ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)
Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus->ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)
Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->openrlhf==0.5.0) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->openrlhf==0.5.0) (2024.1)
Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->openrlhf==0.5.0) (2024.1)
Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open->ray[default]==2.12.0->openrlhf==0.5.0) (1.16.0)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openrlhf==0.5.0) (1.3.0)
Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->openrlhf==0.5.0)
  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)
Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)
Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading proto_plus-1.26.0-py3-none-any.whl.metadata (2.2 kB)
Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->openrlhf==0.5.0) (0.6.0)
Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->openrlhf==0.5.0) (3.2.2)
Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.2.0->memray->ray[default]==2.12.0->openrlhf==0.5.0) (3.0.0)
Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.2.0->memray->ray[default]==2.12.0->openrlhf==0.5.0) (2.18.0)
Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.2.0->memray->ray[default]==2.12.0->openrlhf==0.5.0) (0.1.2)
Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default]==2.12.0->openrlhf==0.5.0) (0.4.1)
Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading linkify_it_py-2.0.3-py3-none-any.whl.metadata (8.5 kB)
Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading uc_micro_py-1.0.3-py3-none-any.whl.metadata (2.0 kB)
Downloading ray-2.12.0-cp310-cp310-manylinux2014_x86_64.whl (65.3 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 65.3/65.3 MB 34.8 MB/s eta 0:00:00
Downloading transformers-4.46.1-py3-none-any.whl (10.0 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10.0/10.0 MB 34.9 MB/s eta 0:00:00
Downloading accelerate-1.3.0-py3-none-any.whl (336 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 336.6/336.6 kB 27.9 MB/s eta 0:00:00
Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 69.7/69.7 MB 35.8 MB/s eta 0:00:00
Downloading datasets-3.2.0-py3-none-any.whl (480 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 480.6/480.6 kB 25.3 MB/s eta 0:00:00
Downloading isort-6.0.0-py3-none-any.whl (94 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 94.1/94.1 kB 23.6 MB/s eta 0:00:00
Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)
Downloading loralib-0.1.2-py3-none-any.whl (10 kB)
Downloading optimum-1.24.0-py3-none-any.whl (433 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 433.6/433.6 kB 31.3 MB/s eta 0:00:00
Downloading peft-0.14.0-py3-none-any.whl (374 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 374.8/374.8 kB 46.3 MB/s eta 0:00:00
Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 927.3/927.3 kB 29.9 MB/s eta 0:00:00
Downloading wandb-0.19.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.9 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20.9/20.9 MB 34.3 MB/s eta 0:00:00
Downloading dill-0.3.8-py3-none-any.whl (116 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 116.3/116.3 kB 40.5 MB/s eta 0:00:00
Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)
Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 207.6/207.6 kB 31.6 MB/s eta 0:00:00
Downloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 464.1/464.1 kB 35.0 MB/s eta 0:00:00
Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 134.8/134.8 kB 62.5 MB/s eta 0:00:00
Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.7 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.7/2.7 MB 32.0 MB/s eta 0:00:00
Downloading pyarrow-19.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.1 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 42.1/42.1 MB 33.0 MB/s eta 0:00:00
Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 462.0/462.0 kB 30.4 MB/s eta 0:00:00
Downloading sentry_sdk-2.20.0-py2.py3-none-any.whl (322 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 322.6/322.6 kB 48.5 MB/s eta 0:00:00
Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.0/3.0 MB 31.6 MB/s eta 0:00:00
Downloading virtualenv-20.29.2-py3-none-any.whl (4.3 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.3/4.3 MB 35.8 MB/s eta 0:00:00
Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)
Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 201.4/201.4 kB 23.6 MB/s eta 0:00:00
Downloading hjson-3.1.0-py3-none-any.whl (54 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 54.0/54.0 kB 111.0 MB/s eta 0:00:00
Downloading memray-1.15.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (8.3 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 8.3/8.3 MB 35.1 MB/s eta 0:00:00
Downloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 44.4/44.4 kB 212.2 MB/s eta 0:00:00
Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 128.2/128.2 kB 25.1 MB/s eta 0:00:00
Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)
Downloading setproctitle-1.3.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)
Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 194.1/194.1 kB 20.7 MB/s eta 0:00:00
Downloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 469.0/469.0 kB 40.3 MB/s eta 0:00:00
Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 62.8/62.8 kB 80.0 MB/s eta 0:00:00
Downloading google_api_core-2.24.1-py3-none-any.whl (160 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 160.1/160.1 kB 37.6 MB/s eta 0:00:00
Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)
Downloading textual-1.0.0-py3-none-any.whl (660 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 660.5/660.5 kB 25.6 MB/s eta 0:00:00
Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 221.7/221.7 kB 25.2 MB/s eta 0:00:00
Downloading proto_plus-1.26.0-py3-none-any.whl (50 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 50.2/50.2 kB 39.6 MB/s eta 0:00:00
Downloading smmap-5.0.2-py3-none-any.whl (24 kB)
Downloading linkify_it_py-2.0.3-py3-none-any.whl (19 kB)
Downloading uc_micro_py-1.0.3-py3-none-any.whl (6.2 kB)
Building wheels for collected packages: openrlhf, deepspeed, flash-attn, transformers_stream_generator, word2number, zss
  Building editable for openrlhf (pyproject.toml): started
  Building editable for openrlhf (pyproject.toml): finished with status 'done'
  Created wheel for openrlhf: filename=openrlhf-0.5.0-0.editable-py3-none-any.whl size=9753 sha256=ff042e61714c4ad34f87dd43be0daa7c4216dfa1da58ab1ac9859631d94f3dfc
  Stored in directory: /tmp/pip-ephem-wheel-cache-pp1k5_my/wheels/dc/6c/8d/2965fd3a9fbd2c9795221c5247dd05589758e834ff0668ae63
  Building wheel for deepspeed (setup.py): started
  Building wheel for deepspeed (setup.py): finished with status 'done'
  Created wheel for deepspeed: filename=deepspeed-0.15.0-py3-none-any.whl size=1483703 sha256=43e09b90c42df90b1320528fb86e4bea0d6400b29996799d3812d81bd73422eb
  Stored in directory: /tmp/pip-ephem-wheel-cache-pp1k5_my/wheels/46/5a/dd/2f36986baec22867dab84e6176db30353ef54e7415cce5f2e0
  Building wheel for flash-attn (setup.py): started
  Building wheel for flash-attn (setup.py): finished with status 'done'
  Created wheel for flash-attn: filename=flash_attn-2.6.1-cp310-cp310-linux_x86_64.whl size=198469920 sha256=f60a6af22f14861a83dd8107698e876716f6b5a57458ce333dfdca27c04b5c6e
  Stored in directory: /tmp/pip-ephem-wheel-cache-pp1k5_my/wheels/91/6a/38/f0faa036b4ac73a73247386f1ab1bb4cb4f6e72e6861a779f1
  Building wheel for transformers_stream_generator (setup.py): started
  Building wheel for transformers_stream_generator (setup.py): finished with status 'done'
  Created wheel for transformers_stream_generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12425 sha256=0c9a92a75c83ba95d6f55cc51a5fb8a58748858f2f93551becd7348219359998
  Stored in directory: /tmp/pip-ephem-wheel-cache-pp1k5_my/wheels/95/4a/90/140f7b67d125906f6a165f38aad212ecb4a695ad0d87582437
  Building wheel for word2number (setup.py): started
  Building wheel for word2number (setup.py): finished with status 'done'
  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5566 sha256=0d882601e2e44b7f2ae0c593ea4f3b90cdb42f7af6065a761eea296efe96e59d
  Stored in directory: /tmp/pip-ephem-wheel-cache-pp1k5_my/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b
  Building wheel for zss (setup.py): started
  Building wheel for zss (setup.py): finished with status 'done'
  Created wheel for zss: filename=zss-1.2.0-py3-none-any.whl size=6724 sha256=0fb9a1a455bacfefd64edd280f9986677543dcff6b7640cc0c3a6f3420aaa2ca
  Stored in directory: /tmp/pip-ephem-wheel-cache-pp1k5_my/wheels/f6/61/2a/cf33ab7301cc318a13418d9a805c1832be561b46e7d9337625
Successfully built openrlhf deepspeed flash-attn transformers_stream_generator word2number zss
Installing collected packages: word2number, py-spy, py-cpuinfo, opencensus-context, nvidia-ml-py, hjson, distlib, colorful, zss, xxhash, virtualenv, uc-micro-py, smmap, setproctitle, sentry-sdk, safetensors, pyarrow, proto-plus, loralib, jsonlines, isort, googleapis-common-protos, docker-pycreds, dill, multiprocess, linkify-it-py, huggingface-hub, gitdb, torchmetrics, tokenizers, google-api-core, gitpython, flash-attn, deepspeed, bitsandbytes, aiohttp-cors, accelerate, wandb, transformers, textual, ray, opencensus, datasets, transformers_stream_generator, peft, optimum, memray, openrlhf
  Attempting uninstall: pyarrow
    Found existing installation: pyarrow 14.0.2
    Uninstalling pyarrow-14.0.2:
      Successfully uninstalled pyarrow-14.0.2
  Attempting uninstall: flash-attn
    Found existing installation: flash-attn 2.4.2
    Uninstalling flash-attn-2.4.2:
      Successfully uninstalled flash-attn-2.4.2
Successfully installed accelerate-1.3.0 aiohttp-cors-0.7.0 bitsandbytes-0.45.2 colorful-0.5.6 datasets-3.2.0 deepspeed-0.15.0 dill-0.3.8 distlib-0.3.9 docker-pycreds-0.4.0 flash-attn-2.6.1 gitdb-4.0.12 gitpython-3.1.44 google-api-core-2.24.1 googleapis-common-protos-1.66.0 hjson-3.1.0 huggingface-hub-0.28.1 isort-6.0.0 jsonlines-4.0.0 linkify-it-py-2.0.3 loralib-0.1.2 memray-1.15.0 multiprocess-0.70.16 nvidia-ml-py-12.570.86 opencensus-0.11.4 opencensus-context-0.1.3 openrlhf-0.5.0 optimum-1.24.0 peft-0.14.0 proto-plus-1.26.0 py-cpuinfo-9.0.0 py-spy-0.4.0 pyarrow-19.0.0 ray-2.12.0 safetensors-0.5.2 sentry-sdk-2.20.0 setproctitle-1.3.4 smmap-5.0.2 textual-1.0.0 tokenizers-0.20.3 torchmetrics-1.6.1 transformers-4.46.1 transformers_stream_generator-0.0.5 uc-micro-py-1.0.3 virtualenv-20.29.2 wandb-0.19.6 word2number-1.1 xxhash-3.5.0 zss-1.2.0
/workspace/hdfs/model_hub
Number of examples in SWE-bench_oracle: 18817
Finished processing SWE-bench_oracle.
Number of examples that need import: 5803
Number of remain instances: 13014
2025-02-12 09:49:47,678	INFO usage_lib.py:469 -- Usage stats collection is enabled by default without user confirmation because this terminal is detected to be non-interactive. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.
2025-02-12 09:49:47,678	INFO scripts.py:764 -- [37mLocal node IP[39m: [1m0.0.0.0[22m
2025-02-12 09:49:50,882	SUCC scripts.py:801 -- [32m--------------------[39m
2025-02-12 09:49:50,882	SUCC scripts.py:802 -- [32mRay runtime started.[39m
2025-02-12 09:49:50,882	SUCC scripts.py:803 -- [32m--------------------[39m
2025-02-12 09:49:50,882	INFO scripts.py:805 -- [36mNext steps[39m
2025-02-12 09:49:50,883	INFO scripts.py:808 -- To add another node to this Ray cluster, run
2025-02-12 09:49:50,883	INFO scripts.py:811 -- [1m  ray start --address='0.0.0.0:6379'[22m
2025-02-12 09:49:50,883	INFO scripts.py:820 -- To connect to this Ray cluster:
2025-02-12 09:49:50,883	INFO scripts.py:822 -- [35mimport[39m[26m ray
2025-02-12 09:49:50,883	INFO scripts.py:823 -- ray[35m.[39m[26minit(_node_ip_address[35m=[39m[26m[33m'0.0.0.0'[39m[26m)
2025-02-12 09:49:50,883	INFO scripts.py:835 -- To submit a Ray job using the Ray Jobs CLI:
2025-02-12 09:49:50,883	INFO scripts.py:836 -- [1m  RAY_ADDRESS='http://127.0.0.1:8265' ray job submit --working-dir . -- python my_script.py[22m
2025-02-12 09:49:50,883	INFO scripts.py:845 -- See https://docs.ray.io/en/latest/cluster/running-applications/job-submission/index.html 
2025-02-12 09:49:50,883	INFO scripts.py:849 -- for more information on submitting Ray jobs to the Ray cluster.
2025-02-12 09:49:50,883	INFO scripts.py:854 -- To terminate the Ray runtime, run
2025-02-12 09:49:50,883	INFO scripts.py:855 -- [1m  ray stop[22m
2025-02-12 09:49:50,883	INFO scripts.py:858 -- To view the status of the cluster, use
2025-02-12 09:49:50,883	INFO scripts.py:859 --   [1mray status[22m[26m
2025-02-12 09:49:50,884	INFO scripts.py:863 -- To monitor and debug Ray, view the dashboard at 
2025-02-12 09:49:50,884	INFO scripts.py:864 --   [1m127.0.0.1:8265[22m[26m
2025-02-12 09:49:50,884	INFO scripts.py:871 -- [4mIf connection to the dashboard fails, check your firewall settings and network configuration.[24m
2025-02-12 09:49:51,811	INFO cli.py:36 -- [37mJob submission server address[39m: [1mhttp://127.0.0.1:8265[22m
2025-02-12 09:49:57,127	SUCC cli.py:60 -- [32m-------------------------------------------------------[39m
2025-02-12 09:49:57,127	SUCC cli.py:61 -- [32mJob 'raysubmit_tHCxHjjq4PmahP8S' submitted successfully[39m
2025-02-12 09:49:57,127	SUCC cli.py:62 -- [32m-------------------------------------------------------[39m
2025-02-12 09:49:57,127	INFO cli.py:286 -- [36mNext steps[39m
2025-02-12 09:49:57,127	INFO cli.py:287 -- Query the logs of the job:
2025-02-12 09:49:57,127	INFO cli.py:289 -- [1mray job logs raysubmit_tHCxHjjq4PmahP8S[22m
2025-02-12 09:49:57,127	INFO cli.py:291 -- Query the status of the job:
2025-02-12 09:49:57,127	INFO cli.py:293 -- [1mray job status raysubmit_tHCxHjjq4PmahP8S[22m
2025-02-12 09:49:57,127	INFO cli.py:295 -- Request the job to be stopped:
2025-02-12 09:49:57,127	INFO cli.py:297 -- [1mray job stop raysubmit_tHCxHjjq4PmahP8S[22m
2025-02-12 09:49:57,131	INFO cli.py:304 -- Tailing logs until the job exits (disable with --no-wait):
[2025-02-12 09:50:09,813] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
df: /root/.triton/autotune: No such file or directory
The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.

0it [00:00, ?it/s]
0it [00:00, ?it/s]
===============================
============ Finish configuring strategy ============
2025-02-12 09:50:14,145	INFO worker.py:1429 -- Using address 0.0.0.0:6379 set in the environment variable RAY_ADDRESS
2025-02-12 09:50:14,145	INFO worker.py:1564 -- Connecting to existing Ray cluster at address: 0.0.0.0:6379...
2025-02-12 09:50:14,156	INFO worker.py:1740 -- Connected to Ray cluster. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
============ Finish creating placement group ============
[36m(pid=3611)[0m [2025-02-12 09:50:18,353] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
============ Finish creating actor model ============
[36m(pid=3738)[0m [2025-02-12 09:50:26,126] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(pid=3739)[0m [2025-02-12 09:50:26,514] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
============ Finish creating reference model ============
============ Creating critic model ============
[36m(pid=4209)[0m [2025-02-12 09:50:34,626] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
============ Finish creating critic model ============
============ Init models ============
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:50:39,482] [INFO] [comm.py:652:init_distributed] cdb=None
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:50:39,483] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[36m(ActorModelRayActorBOX pid=3611)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorModelRayActorBOX pid=3611)[0m Actor(
[36m(ActorModelRayActorBOX pid=3611)[0m   (model): Qwen2ForCausalLM(
[36m(ActorModelRayActorBOX pid=3611)[0m     (model): Qwen2Model(
[36m(ActorModelRayActorBOX pid=3611)[0m       (embed_tokens): Embedding(151936, 1536)
[36m(ActorModelRayActorBOX pid=3611)[0m       (layers): ModuleList(
[36m(ActorModelRayActorBOX pid=3611)[0m         (0-27): 28 x Qwen2DecoderLayer(
[36m(ActorModelRayActorBOX pid=3611)[0m           (self_attn): Qwen2FlashAttention2(
[36m(ActorModelRayActorBOX pid=3611)[0m             (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
[36m(ActorModelRayActorBOX pid=3611)[0m             (k_proj): Linear(in_features=1536, out_features=256, bias=True)
[36m(ActorModelRayActorBOX pid=3611)[0m             (v_proj): Linear(in_features=1536, out_features=256, bias=True)
[36m(ActorModelRayActorBOX pid=3611)[0m             (o_proj): Linear(in_features=1536, out_features=1536, bias=False)
[36m(ActorModelRayActorBOX pid=3611)[0m             (rotary_emb): Qwen2RotaryEmbedding()
[36m(ActorModelRayActorBOX pid=3611)[0m           )
[36m(ActorModelRayActorBOX pid=3611)[0m           (mlp): Qwen2MLP(
[36m(ActorModelRayActorBOX pid=3611)[0m             (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)
[36m(ActorModelRayActorBOX pid=3611)[0m             (up_proj): Linear(in_features=1536, out_features=8960, bias=False)
[36m(ActorModelRayActorBOX pid=3611)[0m             (down_proj): Linear(in_features=8960, out_features=1536, bias=False)
[36m(ActorModelRayActorBOX pid=3611)[0m             (act_fn): SiLU()
[36m(ActorModelRayActorBOX pid=3611)[0m           )
[36m(ActorModelRayActorBOX pid=3611)[0m           (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
[36m(ActorModelRayActorBOX pid=3611)[0m           (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
[36m(ActorModelRayActorBOX pid=3611)[0m         )
[36m(ActorModelRayActorBOX pid=3611)[0m       )
[36m(ActorModelRayActorBOX pid=3611)[0m       (norm): Qwen2RMSNorm((1536,), eps=1e-06)
[36m(ActorModelRayActorBOX pid=3611)[0m       (rotary_emb): Qwen2RotaryEmbedding()
[36m(ActorModelRayActorBOX pid=3611)[0m     )
[36m(ActorModelRayActorBOX pid=3611)[0m     (lm_head): Linear(in_features=1536, out_features=151936, bias=False)
[36m(ActorModelRayActorBOX pid=3611)[0m   )
[36m(ActorModelRayActorBOX pid=3611)[0m )
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:39,689] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.15.0, git-hash=unknown, git-branch=unknown
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:39,689] [INFO] [comm.py:677:init_distributed] Distributed backend already initialized
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:39,689] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4
[36m(pid=4212)[0m [2025-02-12 09:50:34,850] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)[32m [repeated 3x across cluster][0m
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:42,685] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:42,687] [INFO] [logging.py:96:log_dist] [Rank 0] Creating BF16 optimizer
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:42,926] [INFO] [utils.py:781:see_memory_usage] begin bf16_optimizer
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:42,927] [INFO] [utils.py:782:see_memory_usage] MA 3.31 GB         Max_MA 3.31 GB         CA 3.5 GB         Max_CA 3 GB 
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:42,928] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 18.97 GB, percent = 3.8%
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,148] [INFO] [utils.py:781:see_memory_usage] end bf16_ optimizer
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,149] [INFO] [utils.py:782:see_memory_usage] MA 3.31 GB         Max_MA 3.31 GB         CA 3.5 GB         Max_CA 3 GB 
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,149] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 18.97 GB, percent = 3.8%
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,150] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,151] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
[36m(ReferenceModelRayActor pid=3740)[0m     "partition_activations": false, 
[36m(ReferenceModelRayActor pid=3740)[0m     "contiguous_memory_optimization": false, 
[36m(ReferenceModelRayActor pid=3740)[0m     "cpu_checkpointing": false, 
[36m(ReferenceModelRayActor pid=3740)[0m     "number_checkpoints": null, 
[36m(ReferenceModelRayActor pid=3740)[0m     "synchronize_checkpoint_boundary": false, 
[36m(ReferenceModelRayActor pid=3740)[0m     "profile": false
[36m(ReferenceModelRayActor pid=3740)[0m }
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,151] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,151] [INFO] [config.py:1003:print]   amp_enabled .................. False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,151] [INFO] [config.py:1003:print]   amp_params ................... False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,151] [INFO] [config.py:1003:print]   autotuning_config ............ {
[36m(ReferenceModelRayActor pid=3740)[0m     "enabled": false, 
[36m(ReferenceModelRayActor pid=3740)[0m     "start_step": null, 
[36m(ReferenceModelRayActor pid=3740)[0m     "end_step": null, 
[36m(ReferenceModelRayActor pid=3740)[0m     "metric_path": null, 
[36m(ReferenceModelRayActor pid=3740)[0m     "arg_mappings": null, 
[36m(ReferenceModelRayActor pid=3740)[0m     "metric": "throughput", 
[36m(ReferenceModelRayActor pid=3740)[0m     "model_info": null, 
[36m(ReferenceModelRayActor pid=3740)[0m     "results_dir": "autotuning_results", 
[36m(ReferenceModelRayActor pid=3740)[0m     "exps_dir": "autotuning_exps", 
[36m(ReferenceModelRayActor pid=3740)[0m     "overwrite": true, 
[36m(ReferenceModelRayActor pid=3740)[0m     "fast": true, 
[36m(ReferenceModelRayActor pid=3740)[0m     "start_profile_step": 3, 
[36m(ReferenceModelRayActor pid=3740)[0m     "end_profile_step": 5, 
[36m(ReferenceModelRayActor pid=3740)[0m     "tuner_type": "gridsearch", 
[36m(ReferenceModelRayActor pid=3740)[0m     "tuner_early_stopping": 5, 
[36m(ReferenceModelRayActor pid=3740)[0m     "tuner_num_trials": 50, 
[36m(ReferenceModelRayActor pid=3740)[0m     "model_info_path": null, 
[36m(ReferenceModelRayActor pid=3740)[0m     "mp_size": 1, 
[36m(ReferenceModelRayActor pid=3740)[0m     "max_train_batch_size": null, 
[36m(ReferenceModelRayActor pid=3740)[0m     "min_train_batch_size": 1, 
[36m(ReferenceModelRayActor pid=3740)[0m     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[36m(ReferenceModelRayActor pid=3740)[0m     "min_train_micro_batch_size_per_gpu": 1, 
[36m(ReferenceModelRayActor pid=3740)[0m     "num_tuning_micro_batch_sizes": 3
[36m(ReferenceModelRayActor pid=3740)[0m }
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,151] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,151] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,151] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,151] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,151] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,151] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f49544e28f0>
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,151] [INFO] [config.py:1003:print]   communication_data_type ...... None
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,151] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,151] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   disable_allgather ............ False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   dump_state ................... False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
[36m(ReferenceModelRayActor pid=3740)[0m     "enabled": false, 
[36m(ReferenceModelRayActor pid=3740)[0m     "recompute_fwd_factor": 0.0, 
[36m(ReferenceModelRayActor pid=3740)[0m     "profile_step": 1, 
[36m(ReferenceModelRayActor pid=3740)[0m     "module_depth": -1, 
[36m(ReferenceModelRayActor pid=3740)[0m     "top_modules": 1, 
[36m(ReferenceModelRayActor pid=3740)[0m     "detailed": true, 
[36m(ReferenceModelRayActor pid=3740)[0m     "output_file": null
[36m(ReferenceModelRayActor pid=3740)[0m }
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   global_rank .................. 0
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   grad_accum_dtype ............. None
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 16
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   gradient_clipping ............ 1.0
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,152] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   nebula_config ................ {
[36m(ReferenceModelRayActor pid=3740)[0m     "enabled": false, 
[36m(ReferenceModelRayActor pid=3740)[0m     "persistent_storage_path": null, 
[36m(ReferenceModelRayActor pid=3740)[0m     "persistent_time_interval": 100, 
[36m(ReferenceModelRayActor pid=3740)[0m     "num_of_version_in_retention": 2, 
[36m(ReferenceModelRayActor pid=3740)[0m     "enable_nebula_load": true, 
[36m(ReferenceModelRayActor pid=3740)[0m     "load_path": null
[36m(ReferenceModelRayActor pid=3740)[0m }
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   optimizer_name ............... None
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   optimizer_params ............. None
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   pld_enabled .................. False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   pld_params ................... False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   scheduler_name ............... None
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   scheduler_params ............. None
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   sparse_attention ............. None
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   steps_per_print .............. 100
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   train_batch_size ............. 128
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  2
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   world_size ................... 4
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=True) offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   zero_enabled ................. False
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 0
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:43,153] [INFO] [config.py:989:print_user_config]   json = {
[36m(ReferenceModelRayActor pid=3740)[0m     "steps_per_print": 100, 
[36m(ReferenceModelRayActor pid=3740)[0m     "zero_optimization": {
[36m(ReferenceModelRayActor pid=3740)[0m         "stage": 0, 
[36m(ReferenceModelRayActor pid=3740)[0m         "stage3_param_persistence_threshold": "auto", 
[36m(ReferenceModelRayActor pid=3740)[0m         "offload_param": {
[36m(ReferenceModelRayActor pid=3740)[0m             "device": "none", 
[36m(ReferenceModelRayActor pid=3740)[0m             "pin_memory": true
[36m(ReferenceModelRayActor pid=3740)[0m         }
[36m(ReferenceModelRayActor pid=3740)[0m     }, 
[36m(ReferenceModelRayActor pid=3740)[0m     "bf16": {
[36m(ReferenceModelRayActor pid=3740)[0m         "enabled": true
[36m(ReferenceModelRayActor pid=3740)[0m     }, 
[36m(ReferenceModelRayActor pid=3740)[0m     "gradient_clipping": 1.0, 
[36m(ReferenceModelRayActor pid=3740)[0m     "prescale_gradients": false, 
[36m(ReferenceModelRayActor pid=3740)[0m     "wall_clock_breakdown": false, 
[36m(ReferenceModelRayActor pid=3740)[0m     "train_micro_batch_size_per_gpu": 2, 
[36m(ReferenceModelRayActor pid=3740)[0m     "train_batch_size": 128
[36m(ReferenceModelRayActor pid=3740)[0m }
[36m(ActorModelRayActorBOX pid=3611)[0m Using /root/.cache/torch_extensions/py310_cu125 as PyTorch extensions root...
[36m(ActorModelRayActorBOX pid=3611)[0m Creating extension directory /root/.cache/torch_extensions/py310_cu125/cpu_adam...
[36m(ActorModelRayActorBOX pid=3611)[0m Emitting ninja build file /root/.cache/torch_extensions/py310_cu125/cpu_adam/build.ninja...
[36m(ActorModelRayActorBOX pid=3611)[0m Building extension module cpu_adam...
[36m(ActorModelRayActorBOX pid=3611)[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[36m(ActorModelRayActorBOX pid=3611)[0m [1/3] c++ -MMD -MF cpu_adam.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -I/usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/includes -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.10/dist-packages/torch/include/THC -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/usr/local/cuda/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX256__ -D__ENABLE_CUDA__ -DBF16_AVAILABLE -c /usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/adam/cpu_adam.cpp -o cpu_adam.o 
[36m(ActorModelRayActorBOX pid=3737)[0m [2025-02-12 09:50:39,487] [INFO] [comm.py:652:init_distributed] cdb=None[32m [repeated 7x across cluster][0m
[36m(ReferenceModelRayActor pid=3740)[0m [2025-02-12 09:50:39,483] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[36m(ReferenceModelRayActor pid=3740)[0m Actor(
[36m(ReferenceModelRayActor pid=3740)[0m     (model): Qwen2Model([32m [repeated 2x across cluster][0m
[36m(ReferenceModelRayActor pid=3740)[0m       (embed_tokens): Embedding(151936, 1536)
[36m(ReferenceModelRayActor pid=3740)[0m       (layers): ModuleList(
[36m(ReferenceModelRayActor pid=3740)[0m         (0-27): 28 x Qwen2DecoderLayer(
[36m(ReferenceModelRayActor pid=3740)[0m           (self_attn): Qwen2FlashAttention2(
[36m(ReferenceModelRayActor pid=3740)[0m             (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
[36m(ReferenceModelRayActor pid=3740)[0m             (k_proj): Linear(in_features=1536, out_features=256, bias=True)
[36m(ReferenceModelRayActor pid=3740)[0m             (v_proj): Linear(in_features=1536, out_features=256, bias=True)
[36m(ReferenceModelRayActor pid=3740)[0m             (o_proj): Linear(in_features=1536, out_features=1536, bias=False)
[36m(ReferenceModelRayActor pid=3740)[0m       (rotary_emb): Qwen2RotaryEmbedding()[32m [repeated 2x across cluster][0m
[36m(ReferenceModelRayActor pid=3740)[0m )[32m [repeated 7x across cluster][0m
[36m(ReferenceModelRayActor pid=3740)[0m           (mlp): Qwen2MLP(
[36m(ReferenceModelRayActor pid=3740)[0m             (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)
[36m(ReferenceModelRayActor pid=3740)[0m             (up_proj): Linear(in_features=1536, out_features=8960, bias=False)
[36m(ReferenceModelRayActor pid=3740)[0m             (down_proj): Linear(in_features=8960, out_features=1536, bias=False)
[36m(ReferenceModelRayActor pid=3740)[0m             (act_fn): SiLU()
[36m(ReferenceModelRayActor pid=3740)[0m           (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
[36m(ReferenceModelRayActor pid=3740)[0m           (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
[36m(ReferenceModelRayActor pid=3740)[0m       (norm): Qwen2RMSNorm((1536,), eps=1e-06)
[36m(ReferenceModelRayActor pid=3740)[0m     (lm_head): Linear(in_features=1536, out_features=151936, bias=False)
[36m(ReferenceModelRayActor pid=4211)[0m [2025-02-12 09:50:39,760] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4[32m [repeated 3x across cluster][0m
[36m(pid=4701)[0m [2025-02-12 09:50:43,341] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3611)[0m [2/3] c++ -MMD -MF cpu_adam_impl.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -I/usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/includes -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.10/dist-packages/torch/include/THC -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/usr/local/cuda/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX256__ -D__ENABLE_CUDA__ -DBF16_AVAILABLE -c /usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/adam/cpu_adam_impl.cpp -o cpu_adam_impl.o 
[36m(ActorModelRayActorBOX pid=3611)[0m [3/3] c++ cpu_adam.o cpu_adam_impl.o -shared -lcurand -L/usr/local/cuda/lib64 -L/usr/local/lib/python3.10/dist-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o cpu_adam.so
[36m(ActorModelRayActorBOX pid=3611)[0m Time to load cpu_adam op: 28.189892768859863 seconds
[36m(ActorModelRayActorBOX pid=3611)[0m dataset: data/swebench_oracle.json
[36m(ActorModelRayActorBOX pid=3611)[0m Loading extension module cpu_adam...
[36m(ReferenceModelRayActor pid=4211)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
[36m(ActorModelRayActorBOX pid=3739)[0m Using /root/.cache/torch_extensions/py310_cu125 as PyTorch extensions root...[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 0 examples [00:00, ? examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 172 examples [00:00, 1211.36 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 341 examples [00:00, 1272.46 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 513 examples [00:00, 1359.54 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 683 examples [00:00, 1371.63 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 869 examples [00:00, 1448.08 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 1024 examples [00:00, 1398.96 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 1221 examples [00:00, 1508.06 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 1378 examples [00:00, 1463.49 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 1531 examples [00:01, 1420.69 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 1678 examples [00:01, 1388.65 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 1847 examples [00:01, 1438.46 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 2026 examples [00:01, 1509.28 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 2190 examples [00:01, 1442.05 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 2354 examples [00:01, 1449.33 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 2527 examples [00:01, 1511.16 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 2705 examples [00:01, 1534.11 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 2895 examples [00:01, 1562.55 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 3057 examples [00:02, 1521.78 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 3218 examples [00:02, 1476.75 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 3427 examples [00:02, 1584.19 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 3599 examples [00:02, 1579.68 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 3783 examples [00:02, 1595.30 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 4000 examples [00:02, 1475.40 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 4169 examples [00:02, 1481.12 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 4330 examples [00:02, 1448.34 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 4562 examples [00:03, 1403.28 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 4717 examples [00:03, 1402.59 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 4875 examples [00:03, 1394.59 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 5051 examples [00:03, 1412.70 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 5214 examples [00:03, 1413.27 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 5391 examples [00:03, 1189.39 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 5564 examples [00:03, 1270.41 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 5754 examples [00:04, 1386.99 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 5915 examples [00:04, 1414.69 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 6107 examples [00:04, 1484.68 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 6288 examples [00:04, 1523.56 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 6503 examples [00:04, 1432.71 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 6702 examples [00:04, 1534.12 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 6872 examples [00:04, 1548.56 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 7036 examples [00:04, 1505.10 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 7231 examples [00:05, 1366.89 examples/s]
[36m(ActorModelRayActorBOX pid=3738)[0m Loading extension module cpu_adam...[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 7400 examples [00:05, 1400.69 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 7574 examples [00:05, 1446.70 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 7749 examples [00:05, 1435.11 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 7916 examples [00:05, 1447.10 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 8148 examples [00:05, 1422.78 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 8333 examples [00:05, 1485.39 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 8487 examples [00:05, 1446.23 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 8676 examples [00:06, 1308.36 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 8863 examples [00:06, 1387.70 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 9014 examples [00:06, 1381.06 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 9208 examples [00:06, 1478.73 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 9373 examples [00:06, 1468.23 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 9571 examples [00:06, 1549.55 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 9765 examples [00:06, 1603.74 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 9977 examples [00:06, 1470.86 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 10134 examples [00:07, 1443.61 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 10315 examples [00:07, 1479.31 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 10531 examples [00:07, 1387.76 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 10730 examples [00:07, 1477.49 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 10951 examples [00:07, 1374.42 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 11108 examples [00:07, 1376.70 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 11290 examples [00:07, 1453.64 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 11457 examples [00:07, 1467.64 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 11631 examples [00:08, 1471.35 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 11820 examples [00:08, 1533.04 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 11983 examples [00:08, 1516.07 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 12152 examples [00:08, 1514.77 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 12316 examples [00:08, 1456.63 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 12520 examples [00:08, 1528.45 examples/s]
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 12713 examples [00:08, 1515.42 examples/s]
[36m(ActorModelRayActorBOX pid=3611)[0m loaded data/swebench_oracle.json with data_files=data/swebench_oracle.json
[36m(ActorModelRayActorBOX pid=3611)[0m [Dataset({
[36m(ActorModelRayActorBOX pid=3611)[0m     features: ['instance_id', 'input', 'ground_truth_answer', 'answer', 'target', 'commit'],
[36m(ActorModelRayActorBOX pid=3611)[0m     num_rows: 13014
[36m(ActorModelRayActorBOX pid=3611)[0m })]
[36m(ActorModelRayActorBOX pid=3737)[0m Time to load cpu_adam op: 28.236268281936646 seconds[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3739)[0m 
Generating train split: 12959 examples [00:08, 1486.87 examples/s]
Generating train split: 13014 examples [00:08, 1453.48 examples/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:   0%|          | 0/13014 [00:00<?, ?it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:   4%|â–         | 580/13014 [00:00<00:02, 5784.86it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:   9%|â–‰         | 1159/13014 [00:00<00:02, 5217.01it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:  13%|â–ˆâ–        | 1685/13014 [00:00<00:02, 5005.21it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:  17%|â–ˆâ–‹        | 2221/13014 [00:00<00:02, 5124.79it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:  21%|â–ˆâ–ˆ        | 2736/13014 [00:00<00:02, 5102.42it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:  25%|â–ˆâ–ˆâ–       | 3248/13014 [00:00<00:01, 5056.35it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:  29%|â–ˆâ–ˆâ–‰       | 3810/13014 [00:00<00:01, 5212.15it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:  33%|â–ˆâ–ˆâ–ˆâ–      | 4332/13014 [00:00<00:01, 5109.65it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 4844/13014 [00:00<00:01, 4917.50it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 5338/13014 [00:01<00:01, 4887.75it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5850/13014 [00:01<00:01, 4955.42it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 6350/13014 [00:01<00:01, 4967.86it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 6877/13014 [00:01<00:01, 5046.75it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 7383/13014 [00:01<00:01, 4939.80it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 7898/13014 [00:01<00:01, 5000.92it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8421/13014 [00:01<00:00, 5058.88it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 8928/13014 [00:01<00:00, 4879.20it/s]
Preprocessing data:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 9444/13014 [00:01<00:00, 4959.70it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 9967/13014 [00:01<00:00, 5013.95it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 10470/13014 [00:02<00:00, 4987.25it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 10970/13014 [00:02<00:00, 4985.09it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 11487/13014 [00:02<00:00, 5035.84it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11999/13014 [00:02<00:00, 5051.59it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 12519/13014 [00:02<00:00, 5095.63it/s]
[36m(ActorModelRayActorBOX pid=3611)[0m 
Preprocessing data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13014/13014 [00:02<00:00, 5046.84it/s]
[36m(ActorModelRayActorBOX pid=3737)[0m [2025-02-12 09:51:21,781] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:21,928] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.15.0, git-hash=unknown, git-branch=unknown
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:21,929] [INFO] [comm.py:677:init_distributed] Distributed backend already initialized
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:24,098] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:24,100] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:24,100] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:24,113] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:24,113] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:24,113] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:24,113] [INFO] [stage_1_and_2.py:148:__init__] Reduce bucket size 500000000
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:24,113] [INFO] [stage_1_and_2.py:149:__init__] Allgather bucket size 500000000
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:24,113] [INFO] [stage_1_and_2.py:150:__init__] CPU Offload: True
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:24,113] [INFO] [stage_1_and_2.py:151:__init__] Round robin gradient partitioning: False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:29,561] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:29,562] [INFO] [utils.py:782:see_memory_usage] MA 3.75 GB         Max_MA 3.75 GB         CA 3.75 GB         Max_CA 4 GB 
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:29,563] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 51.26 GB, percent = 10.2%
[36m(ActorModelRayActorBOX pid=3739)[0m [2025-02-12 09:51:21,928] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:31,802] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:31,803] [INFO] [utils.py:782:see_memory_usage] MA 3.75 GB         Max_MA 3.75 GB         CA 3.75 GB         Max_CA 4 GB 
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:31,803] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 55.94 GB, percent = 11.1%
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:31,803] [INFO] [stage_1_and_2.py:543:__init__] optimizer state initialized
============ Finish init vLLM ============
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,025] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,026] [INFO] [utils.py:782:see_memory_usage] MA 3.75 GB         Max_MA 3.75 GB         CA 3.75 GB         Max_CA 4 GB 
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,027] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 55.94 GB, percent = 11.1%
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,029] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,029] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,029] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7f8e3444be80>
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,029] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,030] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,031] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
[36m(ActorModelRayActorBOX pid=3611)[0m     "partition_activations": false, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "contiguous_memory_optimization": false, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "cpu_checkpointing": false, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "number_checkpoints": null, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "synchronize_checkpoint_boundary": false, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "profile": false
[36m(ActorModelRayActorBOX pid=3611)[0m }
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,031] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,031] [INFO] [config.py:1003:print]   amp_enabled .................. False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,031] [INFO] [config.py:1003:print]   amp_params ................... False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,031] [INFO] [config.py:1003:print]   autotuning_config ............ {
[36m(ActorModelRayActorBOX pid=3611)[0m     "enabled": false, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "start_step": null, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "end_step": null, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "metric_path": null, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "arg_mappings": null, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "metric": "throughput", 
[36m(ActorModelRayActorBOX pid=3611)[0m     "model_info": null, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "results_dir": "autotuning_results", 
[36m(ActorModelRayActorBOX pid=3611)[0m     "exps_dir": "autotuning_exps", 
[36m(ActorModelRayActorBOX pid=3611)[0m     "overwrite": true, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "fast": true, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "start_profile_step": 3, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "end_profile_step": 5, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "tuner_type": "gridsearch", 
[36m(ActorModelRayActorBOX pid=3611)[0m     "tuner_early_stopping": 5, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "tuner_num_trials": 50, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "model_info_path": null, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "mp_size": 1, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "max_train_batch_size": null, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "min_train_batch_size": 1, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "min_train_micro_batch_size_per_gpu": 1, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "num_tuning_micro_batch_sizes": 3
[36m(ActorModelRayActorBOX pid=3611)[0m }
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,031] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,031] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,031] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,031] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,031] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,031] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f8e2234f700>
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,031] [INFO] [config.py:1003:print]   communication_data_type ...... None
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,031] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,031] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   disable_allgather ............ False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   dump_state ................... False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
[36m(ActorModelRayActorBOX pid=3611)[0m     "enabled": false, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "recompute_fwd_factor": 0.0, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "profile_step": 1, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "module_depth": -1, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "top_modules": 1, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "detailed": true, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "output_file": null
[36m(ActorModelRayActorBOX pid=3611)[0m }
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   global_rank .................. 0
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   grad_accum_dtype ............. fp32
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 16
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   gradient_clipping ............ 1.0
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,032] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   nebula_config ................ {
[36m(ActorModelRayActorBOX pid=3611)[0m     "enabled": false, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "persistent_storage_path": null, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "persistent_time_interval": 100, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "num_of_version_in_retention": 2, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "enable_nebula_load": true, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "load_path": null
[36m(ActorModelRayActorBOX pid=3611)[0m }
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   optimizer_name ............... None
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   optimizer_params ............. None
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   pld_enabled .................. False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   pld_params ................... False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   scheduler_name ............... None
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   scheduler_params ............. None
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   sparse_attention ............. None
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   steps_per_print .............. 100
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   train_batch_size ............. 128
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  2
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   world_size ................... 4
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   zero_enabled ................. True
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,033] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 2
[36m(ActorModelRayActorBOX pid=3611)[0m [2025-02-12 09:51:32,034] [INFO] [config.py:989:print_user_config]   json = {
[36m(ActorModelRayActorBOX pid=3611)[0m     "steps_per_print": 100, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "zero_optimization": {
[36m(ActorModelRayActorBOX pid=3611)[0m         "stage": 2, 
[36m(ActorModelRayActorBOX pid=3611)[0m         "offload_param": {
[36m(ActorModelRayActorBOX pid=3611)[0m             "device": "none"
[36m(ActorModelRayActorBOX pid=3611)[0m         }, 
[36m(ActorModelRayActorBOX pid=3611)[0m         "offload_optimizer": {
[36m(ActorModelRayActorBOX pid=3611)[0m             "device": "cpu", 
[36m(ActorModelRayActorBOX pid=3611)[0m             "pin_memory": true
[36m(ActorModelRayActorBOX pid=3611)[0m         }, 
[36m(ActorModelRayActorBOX pid=3611)[0m         "sub_group_size": "auto", 
[36m(ActorModelRayActorBOX pid=3611)[0m         "stage3_max_live_parameters": "auto", 
[36m(ActorModelRayActorBOX pid=3611)[0m         "stage3_max_reuse_distance": "auto", 
[36m(ActorModelRayActorBOX pid=3611)[0m         "stage3_param_persistence_threshold": "auto", 
[36m(ActorModelRayActorBOX pid=3611)[0m         "stage3_prefetch_bucket_size": "auto", 
[36m(ActorModelRayActorBOX pid=3611)[0m         "reduce_bucket_size": "auto", 
[36m(ActorModelRayActorBOX pid=3611)[0m         "zero_hpz_partition_size": 1, 
[36m(ActorModelRayActorBOX pid=3611)[0m         "zero_quantized_weights": false, 
[36m(ActorModelRayActorBOX pid=3611)[0m         "zero_quantized_gradients": false
[36m(ActorModelRayActorBOX pid=3611)[0m     }, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "bf16": {
[36m(ActorModelRayActorBOX pid=3611)[0m         "enabled": true
[36m(ActorModelRayActorBOX pid=3611)[0m     }, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "gradient_clipping": 1.0, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "prescale_gradients": false, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "wall_clock_breakdown": false, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "data_types": {
[36m(ActorModelRayActorBOX pid=3611)[0m         "grad_accum_dtype": "fp32"
[36m(ActorModelRayActorBOX pid=3611)[0m     }, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "train_micro_batch_size_per_gpu": 2, 
[36m(ActorModelRayActorBOX pid=3611)[0m     "train_batch_size": 128
[36m(ActorModelRayActorBOX pid=3611)[0m }
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:32,044] [INFO] [comm.py:652:init_distributed] cdb=None
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:32,045] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[36m(CriticModelRayActor pid=4212)[0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[36m(CriticModelRayActor pid=4212)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(CriticModelRayActor pid=4212)[0m CriticModel(
[36m(CriticModelRayActor pid=4212)[0m   (model): Qwen2Model(
[36m(CriticModelRayActor pid=4212)[0m     (embed_tokens): Embedding(151936, 1536)
[36m(CriticModelRayActor pid=4212)[0m     (layers): ModuleList(
[36m(CriticModelRayActor pid=4212)[0m       (0-27): 28 x Qwen2DecoderLayer(
[36m(CriticModelRayActor pid=4212)[0m         (self_attn): Qwen2FlashAttention2(
[36m(CriticModelRayActor pid=4212)[0m           (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
[36m(CriticModelRayActor pid=4212)[0m           (k_proj): Linear(in_features=1536, out_features=256, bias=True)
[36m(CriticModelRayActor pid=4212)[0m           (v_proj): Linear(in_features=1536, out_features=256, bias=True)
[36m(CriticModelRayActor pid=4212)[0m           (o_proj): Linear(in_features=1536, out_features=1536, bias=False)
[36m(CriticModelRayActor pid=4212)[0m           (rotary_emb): Qwen2RotaryEmbedding()
[36m(CriticModelRayActor pid=4212)[0m         )
[36m(CriticModelRayActor pid=4212)[0m         (mlp): Qwen2MLP(
[36m(CriticModelRayActor pid=4212)[0m           (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)
[36m(CriticModelRayActor pid=4212)[0m           (up_proj): Linear(in_features=1536, out_features=8960, bias=False)
[36m(CriticModelRayActor pid=4212)[0m           (down_proj): Linear(in_features=8960, out_features=1536, bias=False)
[36m(CriticModelRayActor pid=4212)[0m           (act_fn): SiLU()
[36m(CriticModelRayActor pid=4212)[0m         )
[36m(CriticModelRayActor pid=4212)[0m         (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
[36m(CriticModelRayActor pid=4212)[0m         (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
[36m(CriticModelRayActor pid=4212)[0m       )
[36m(CriticModelRayActor pid=4212)[0m     )
[36m(CriticModelRayActor pid=4212)[0m     (norm): Qwen2RMSNorm((1536,), eps=1e-06)
[36m(CriticModelRayActor pid=4212)[0m     (rotary_emb): Qwen2RotaryEmbedding()
[36m(CriticModelRayActor pid=4212)[0m   )
[36m(CriticModelRayActor pid=4212)[0m   (value_head): Linear(in_features=1536, out_features=1, bias=False)
[36m(CriticModelRayActor pid=4212)[0m )
[36m(CriticModelRayActor pid=4212)[0m reward normalization status: True
[36m(CriticModelRayActor pid=4212)[0m mean: tensor([0.], dtype=torch.bfloat16), std tensor([1.], dtype=torch.bfloat16)
[36m(CriticModelRayActor pid=4212)[0m Some weights of CriticModel were not initialized from the model checkpoint at /workspace/hdfs/model_hub and are newly initialized: ['value_head.weight']
[36m(CriticModelRayActor pid=4212)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(CriticModelRayActor pid=4687)[0m Using /root/.cache/torch_extensions/py310_cu125 as PyTorch extensions root...
[36m(CriticModelRayActor pid=4687)[0m Emitting ninja build file /root/.cache/torch_extensions/py310_cu125/cpu_adam/build.ninja...
[36m(CriticModelRayActor pid=4687)[0m Building extension module cpu_adam...
[36m(CriticModelRayActor pid=4687)[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[36m(CriticModelRayActor pid=4687)[0m Loading extension module cpu_adam...
[36m(CriticModelRayActor pid=4687)[0m ninja: no work to do.
[36m(CriticModelRayActor pid=4687)[0m Time to load cpu_adam op: 2.6130714416503906 seconds
[36m(CriticModelRayActor pid=4687)[0m [2025-02-12 09:51:36,061] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4
[36m(CriticModelRayActor pid=4697)[0m [2025-02-12 09:51:36,219] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:36,283] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.15.0, git-hash=unknown, git-branch=unknown
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:36,283] [INFO] [comm.py:677:init_distributed] Distributed backend already initialized
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:39,338] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:39,340] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:39,340] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:39,353] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:39,353] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:39,354] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:39,354] [INFO] [stage_1_and_2.py:148:__init__] Reduce bucket size 500000000
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:39,354] [INFO] [stage_1_and_2.py:149:__init__] Allgather bucket size 500000000
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:39,354] [INFO] [stage_1_and_2.py:150:__init__] CPU Offload: True
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:39,354] [INFO] [stage_1_and_2.py:151:__init__] Round robin gradient partitioning: False
[36m(CriticModelRayActor pid=4701)[0m [2025-02-12 09:51:32,049] [INFO] [comm.py:652:init_distributed] cdb=None[32m [repeated 3x across cluster][0m
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:44,096] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:44,097] [INFO] [utils.py:782:see_memory_usage] MA 3.31 GB         Max_MA 3.31 GB         CA 3.31 GB         Max_CA 3 GB 
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:44,097] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 81.49 GB, percent = 16.2%
[36m(CriticModelRayActor pid=4697)[0m ninja: no work to do.
[36m(CriticModelRayActor pid=4212)[0m Time to load cpu_adam op: 2.7835705280303955 seconds[32m [repeated 3x across cluster][0m
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:36,283] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4[32m [repeated 2x across cluster][0m
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,272] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,273] [INFO] [utils.py:782:see_memory_usage] MA 3.31 GB         Max_MA 3.31 GB         CA 3.31 GB         Max_CA 3 GB 
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,273] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 85.36 GB, percent = 16.9%
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,273] [INFO] [stage_1_and_2.py:543:__init__] optimizer state initialized
============ Start training ============
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,591] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,591] [INFO] [utils.py:782:see_memory_usage] MA 3.31 GB         Max_MA 3.31 GB         CA 3.31 GB         Max_CA 3 GB 
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,592] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 85.36 GB, percent = 16.9%
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,595] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,595] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,595] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7f199fba4820>
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,596] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,597] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,598] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
[36m(CriticModelRayActor pid=4212)[0m     "partition_activations": false, 
[36m(CriticModelRayActor pid=4212)[0m     "contiguous_memory_optimization": false, 
[36m(CriticModelRayActor pid=4212)[0m     "cpu_checkpointing": false, 
[36m(CriticModelRayActor pid=4212)[0m     "number_checkpoints": null, 
[36m(CriticModelRayActor pid=4212)[0m     "synchronize_checkpoint_boundary": false, 
[36m(CriticModelRayActor pid=4212)[0m     "profile": false
[36m(CriticModelRayActor pid=4212)[0m }
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,598] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,598] [INFO] [config.py:1003:print]   amp_enabled .................. False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,598] [INFO] [config.py:1003:print]   amp_params ................... False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,598] [INFO] [config.py:1003:print]   autotuning_config ............ {
[36m(CriticModelRayActor pid=4212)[0m     "enabled": false, 
[36m(CriticModelRayActor pid=4212)[0m     "start_step": null, 
[36m(CriticModelRayActor pid=4212)[0m     "end_step": null, 
[36m(CriticModelRayActor pid=4212)[0m     "metric_path": null, 
[36m(CriticModelRayActor pid=4212)[0m     "arg_mappings": null, 
[36m(CriticModelRayActor pid=4212)[0m     "metric": "throughput", 
[36m(CriticModelRayActor pid=4212)[0m     "model_info": null, 
[36m(CriticModelRayActor pid=4212)[0m     "results_dir": "autotuning_results", 
[36m(CriticModelRayActor pid=4212)[0m     "exps_dir": "autotuning_exps", 
[36m(CriticModelRayActor pid=4212)[0m     "overwrite": true, 
[36m(CriticModelRayActor pid=4212)[0m     "fast": true, 
[36m(CriticModelRayActor pid=4212)[0m     "start_profile_step": 3, 
[36m(CriticModelRayActor pid=4212)[0m     "end_profile_step": 5, 
[36m(CriticModelRayActor pid=4212)[0m     "tuner_type": "gridsearch", 
[36m(CriticModelRayActor pid=4212)[0m     "tuner_early_stopping": 5, 
[36m(CriticModelRayActor pid=4212)[0m     "tuner_num_trials": 50, 
[36m(CriticModelRayActor pid=4212)[0m     "model_info_path": null, 
[36m(CriticModelRayActor pid=4212)[0m     "mp_size": 1, 
[36m(CriticModelRayActor pid=4212)[0m     "max_train_batch_size": null, 
[36m(CriticModelRayActor pid=4212)[0m     "min_train_batch_size": 1, 
[36m(CriticModelRayActor pid=4212)[0m     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[36m(CriticModelRayActor pid=4212)[0m     "min_train_micro_batch_size_per_gpu": 1, 
[36m(CriticModelRayActor pid=4212)[0m     "num_tuning_micro_batch_sizes": 3
[36m(CriticModelRayActor pid=4212)[0m }
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,598] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,598] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,598] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,598] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,598] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,598] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f199e24be20>
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,598] [INFO] [config.py:1003:print]   communication_data_type ...... None
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,598] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,598] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,598] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,598] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,598] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,598] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,598] [INFO] [config.py:1003:print]   disable_allgather ............ False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,598] [INFO] [config.py:1003:print]   dump_state ................... False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
[36m(CriticModelRayActor pid=4212)[0m     "enabled": false, 
[36m(CriticModelRayActor pid=4212)[0m     "recompute_fwd_factor": 0.0, 
[36m(CriticModelRayActor pid=4212)[0m     "profile_step": 1, 
[36m(CriticModelRayActor pid=4212)[0m     "module_depth": -1, 
[36m(CriticModelRayActor pid=4212)[0m     "top_modules": 1, 
[36m(CriticModelRayActor pid=4212)[0m     "detailed": true, 
[36m(CriticModelRayActor pid=4212)[0m     "output_file": null
[36m(CriticModelRayActor pid=4212)[0m }
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   global_rank .................. 0
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   grad_accum_dtype ............. fp32
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 16
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   gradient_clipping ............ 1.0
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   nebula_config ................ {
[36m(CriticModelRayActor pid=4212)[0m     "enabled": false, 
[36m(CriticModelRayActor pid=4212)[0m     "persistent_storage_path": null, 
[36m(CriticModelRayActor pid=4212)[0m     "persistent_time_interval": 100, 
[36m(CriticModelRayActor pid=4212)[0m     "num_of_version_in_retention": 2, 
[36m(CriticModelRayActor pid=4212)[0m     "enable_nebula_load": true, 
[36m(CriticModelRayActor pid=4212)[0m     "load_path": null
[36m(CriticModelRayActor pid=4212)[0m }
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,599] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   optimizer_name ............... None
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   optimizer_params ............. None
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   pld_enabled .................. False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   pld_params ................... False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   scheduler_name ............... None
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   scheduler_params ............. None
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   sparse_attention ............. None
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   steps_per_print .............. 100
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   train_batch_size ............. 128
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  2
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   world_size ................... 4
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   zero_enabled ................. True
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 2
[36m(CriticModelRayActor pid=4212)[0m [2025-02-12 09:51:46,600] [INFO] [config.py:989:print_user_config]   json = {
[36m(CriticModelRayActor pid=4212)[0m     "steps_per_print": 100, 
[36m(CriticModelRayActor pid=4212)[0m     "zero_optimization": {
[36m(CriticModelRayActor pid=4212)[0m         "stage": 2, 
[36m(CriticModelRayActor pid=4212)[0m         "offload_param": {
[36m(CriticModelRayActor pid=4212)[0m             "device": "none"
[36m(CriticModelRayActor pid=4212)[0m         }, 
[36m(CriticModelRayActor pid=4212)[0m         "offload_optimizer": {
[36m(CriticModelRayActor pid=4212)[0m             "device": "cpu", 
[36m(CriticModelRayActor pid=4212)[0m             "pin_memory": true
[36m(CriticModelRayActor pid=4212)[0m         }, 
[36m(CriticModelRayActor pid=4212)[0m         "sub_group_size": "auto", 
[36m(CriticModelRayActor pid=4212)[0m         "stage3_max_live_parameters": "auto", 
[36m(CriticModelRayActor pid=4212)[0m         "stage3_max_reuse_distance": "auto", 
[36m(CriticModelRayActor pid=4212)[0m         "stage3_param_persistence_threshold": "auto", 
[36m(CriticModelRayActor pid=4212)[0m         "stage3_prefetch_bucket_size": "auto", 
[36m(CriticModelRayActor pid=4212)[0m         "reduce_bucket_size": "auto", 
[36m(CriticModelRayActor pid=4212)[0m         "zero_hpz_partition_size": 1, 
[36m(CriticModelRayActor pid=4212)[0m         "zero_quantized_weights": false, 
[36m(CriticModelRayActor pid=4212)[0m         "zero_quantized_gradients": false
[36m(CriticModelRayActor pid=4212)[0m     }, 
[36m(CriticModelRayActor pid=4212)[0m     "bf16": {
[36m(CriticModelRayActor pid=4212)[0m         "enabled": true
[36m(CriticModelRayActor pid=4212)[0m     }, 
[36m(CriticModelRayActor pid=4212)[0m     "gradient_clipping": 1.0, 
[36m(CriticModelRayActor pid=4212)[0m     "prescale_gradients": false, 
[36m(CriticModelRayActor pid=4212)[0m     "wall_clock_breakdown": false, 
[36m(CriticModelRayActor pid=4212)[0m     "data_types": {
[36m(CriticModelRayActor pid=4212)[0m         "grad_accum_dtype": "fp32"
[36m(CriticModelRayActor pid=4212)[0m     }, 
[36m(CriticModelRayActor pid=4212)[0m     "train_micro_batch_size_per_gpu": 2, 
[36m(CriticModelRayActor pid=4212)[0m     "train_batch_size": 128
[36m(CriticModelRayActor pid=4212)[0m }
[36m(ActorModelRayActorBOX pid=3611)[0m wandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc
[36m(CriticModelRayActor pid=4701)[0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.[32m [repeated 3x across cluster][0m
[36m(CriticModelRayActor pid=4701)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(CriticModelRayActor pid=4701)[0m Some weights of CriticModel were not initialized from the model checkpoint at /workspace/hdfs/model_hub and are newly initialized: ['value_head.weight'][32m [repeated 3x across cluster][0m
[36m(CriticModelRayActor pid=4701)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 3x across cluster][0m
[36m(CriticModelRayActor pid=4701)[0m Using /root/.cache/torch_extensions/py310_cu125 as PyTorch extensions root...[32m [repeated 3x across cluster][0m
[36m(CriticModelRayActor pid=4697)[0m Emitting ninja build file /root/.cache/torch_extensions/py310_cu125/cpu_adam/build.ninja...
[36m(CriticModelRayActor pid=4697)[0m Building extension module cpu_adam...
[36m(CriticModelRayActor pid=4697)[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[36m(CriticModelRayActor pid=4212)[0m Loading extension module cpu_adam...[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3611)[0m wandb: Currently logged in as: sikaili (sikaili-university-of-pennsylvania) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(ActorModelRayActorBOX pid=3611)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(ActorModelRayActorBOX pid=3611)[0m wandb: Tracking run with wandb version 0.19.6
