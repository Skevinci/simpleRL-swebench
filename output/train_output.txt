
=============
== PyTorch ==
=============

NVIDIA Release 24.07 (build 100464919)
PyTorch Version 2.4.0a0+3bcc3cd
Container image Copyright (c) 2024, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Copyright (c) 2014-2024 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com
Obtaining file:///workspace/simpleRL-swebench/train
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Checking if build backend supports build_editable: started
  Checking if build backend supports build_editable: finished with status 'done'
  Getting requirements to build editable: started
  Getting requirements to build editable: finished with status 'done'
  Preparing editable metadata (pyproject.toml): started
  Preparing editable metadata (pyproject.toml): finished with status 'done'
Collecting accelerate (from openrlhf==0.5.0)
  Downloading accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)
Collecting bitsandbytes (from openrlhf==0.5.0)
  Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)
Collecting datasets (from openrlhf==0.5.0)
  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)
Collecting deepspeed==0.15.0 (from openrlhf==0.5.0)
  Downloading deepspeed-0.15.0.tar.gz (1.4 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.4/1.4 MB 23.8 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from openrlhf==0.5.0) (0.8.0)
Collecting flash-attn==2.6.1 (from openrlhf==0.5.0)
  Downloading flash_attn-2.6.1.tar.gz (2.6 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.6/2.6 MB 29.7 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting isort (from openrlhf==0.5.0)
  Downloading isort-6.0.0-py3-none-any.whl.metadata (11 kB)
Collecting jsonlines (from openrlhf==0.5.0)
  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)
Collecting loralib (from openrlhf==0.5.0)
  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)
Collecting optimum (from openrlhf==0.5.0)
  Downloading optimum-1.24.0-py3-none-any.whl.metadata (21 kB)
Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from openrlhf==0.5.0) (24.0)
Collecting peft (from openrlhf==0.5.0)
  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)
Collecting ray==2.12.0 (from ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading ray-2.12.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)
Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from openrlhf==0.5.0) (2.9.0)
Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openrlhf==0.5.0) (2.4.0a0+3bcc3cddb5.nv24.7)
Collecting torchmetrics (from openrlhf==0.5.0)
  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)
Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openrlhf==0.5.0) (4.66.4)
Collecting transformers==4.46.1 (from openrlhf==0.5.0)
  Downloading transformers-4.46.1-py3-none-any.whl.metadata (44 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 44.1/44.1 kB 106.1 MB/s eta 0:00:00
Collecting transformers_stream_generator (from openrlhf==0.5.0)
  Downloading transformers-stream-generator-0.0.5.tar.gz (13 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting wandb (from openrlhf==0.5.0)
  Downloading wandb-0.19.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)
Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from openrlhf==0.5.0) (0.43.0)
Collecting word2number (from openrlhf==0.5.0)
  Downloading word2number-1.1.zip (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting zss (from openrlhf==0.5.0)
  Downloading zss-1.2.0.tar.gz (9.8 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting hjson (from deepspeed==0.15.0->openrlhf==0.5.0)
  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)
Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.15.0->openrlhf==0.5.0) (1.11.1.1)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.15.0->openrlhf==0.5.0) (1.24.4)
Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.15.0->openrlhf==0.5.0) (5.9.8)
Collecting py-cpuinfo (from deepspeed==0.15.0->openrlhf==0.5.0)
  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)
Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.15.0->openrlhf==0.5.0) (2.8.2)
Collecting nvidia-ml-py (from deepspeed==0.15.0->openrlhf==0.5.0)
  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)
Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (8.1.7)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (3.15.4)
Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (4.23.0)
Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (1.0.8)
Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (4.24.4)
Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (6.0.1)
Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (1.3.1)
Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (1.4.1)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (2.32.3)
Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[default]==2.12.0->openrlhf==0.5.0) (3.9.5)
Collecting aiohttp-cors (from ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)
Collecting colorful (from ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)
Collecting py-spy>=0.2.0 (from ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)
Collecting opencensus (from ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)
Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default]==2.12.0->openrlhf==0.5.0) (0.20.0)
Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default]==2.12.0->openrlhf==0.5.0) (7.0.4)
Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading virtualenv-20.29.2-py3-none-any.whl.metadata (4.5 kB)
Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]==2.12.0->openrlhf==0.5.0) (1.62.1)
Collecting memray (from ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading memray-1.15.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (19 kB)
Collecting huggingface-hub<1.0,>=0.23.2 (from transformers==4.46.1->openrlhf==0.5.0)
  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.1->openrlhf==0.5.0) (2024.5.15)
Collecting safetensors>=0.4.1 (from transformers==4.46.1->openrlhf==0.5.0)
  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)
Collecting tokenizers<0.21,>=0.20 (from transformers==4.46.1->openrlhf==0.5.0)
  Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)
Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openrlhf==0.5.0) (4.12.0)
Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openrlhf==0.5.0) (1.13.0)
Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openrlhf==0.5.0) (3.3)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openrlhf==0.5.0) (3.1.4)
Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openrlhf==0.5.0) (2024.5.0)
Collecting pyarrow>=15.0.0 (from datasets->openrlhf==0.5.0)
  Downloading pyarrow-19.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)
Collecting dill<0.3.9,>=0.3.0 (from datasets->openrlhf==0.5.0)
  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)
Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->openrlhf==0.5.0) (2.2.1)
Collecting xxhash (from datasets->openrlhf==0.5.0)
  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)
Collecting multiprocess<0.70.17 (from datasets->openrlhf==0.5.0)
  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)
Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->openrlhf==0.5.0) (23.2.0)
Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openrlhf==0.5.0) (2.1.0)
Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openrlhf==0.5.0) (2.32.0)
Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openrlhf==0.5.0) (0.4.6)
Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openrlhf==0.5.0) (3.6)
Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openrlhf==0.5.0) (68.2.2)
Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openrlhf==0.5.0) (0.6.1)
Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openrlhf==0.5.0) (1.8.1)
Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openrlhf==0.5.0) (3.0.3)
Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages/lightning_utilities-0.11.3.post0-py3.10.egg (from torchmetrics->openrlhf==0.5.0) (0.11.3.post0)
Collecting docker-pycreds>=0.4.0 (from wandb->openrlhf==0.5.0)
  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)
Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->openrlhf==0.5.0)
  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)
Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->openrlhf==0.5.0) (4.2.2)
Collecting sentry-sdk>=2.0.0 (from wandb->openrlhf==0.5.0)
  Downloading sentry_sdk-2.20.0-py2.py3-none-any.whl.metadata (10 kB)
Collecting setproctitle (from wandb->openrlhf==0.5.0)
  Downloading setproctitle-1.3.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)
Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from zss->openrlhf==0.5.0) (1.16.0)
Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]==2.12.0->openrlhf==0.5.0) (6.0.5)
Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]==2.12.0->openrlhf==0.5.0) (1.9.4)
Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]==2.12.0->openrlhf==0.5.0) (4.0.3)
Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->openrlhf==0.5.0)
  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->openrlhf==0.5.0) (5.3.3)
Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->openrlhf==0.5.0) (0.4.0)
Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->openrlhf==0.5.0) (4.9)
Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->openrlhf==0.5.0) (2.0.0)
Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->deepspeed==0.15.0->openrlhf==0.5.0) (0.7.0)
Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->deepspeed==0.15.0->openrlhf==0.5.0) (2.20.1)
Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (3.7)
Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (2.0.7)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (2024.7.4)
Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)
Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->openrlhf==0.5.0) (2.1.5)
Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (2023.12.1)
Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (0.35.1)
Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.12.0->ray[default]==2.12.0->openrlhf==0.5.0) (0.19.0)
Requirement already satisfied: rich>=11.2.0 in /usr/local/lib/python3.10/dist-packages (from memray->ray[default]==2.12.0->openrlhf==0.5.0) (13.7.1)
Collecting textual>=0.41.0 (from memray->ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading textual-1.0.0-py3-none-any.whl.metadata (9.0 kB)
Collecting opencensus-context>=0.1.3 (from opencensus->ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)
Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus->ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)
Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->openrlhf==0.5.0) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->openrlhf==0.5.0) (2024.1)
Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->openrlhf==0.5.0) (2024.1)
Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open->ray[default]==2.12.0->openrlhf==0.5.0) (1.16.0)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openrlhf==0.5.0) (1.3.0)
Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->openrlhf==0.5.0)
  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)
Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)
Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading proto_plus-1.26.0-py3-none-any.whl.metadata (2.2 kB)
Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->openrlhf==0.5.0) (0.6.0)
Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->openrlhf==0.5.0) (3.2.2)
Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.2.0->memray->ray[default]==2.12.0->openrlhf==0.5.0) (3.0.0)
Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.2.0->memray->ray[default]==2.12.0->openrlhf==0.5.0) (2.18.0)
Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.2.0->memray->ray[default]==2.12.0->openrlhf==0.5.0) (0.1.2)
Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading linkify_it_py-2.0.3-py3-none-any.whl.metadata (8.5 kB)
Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default]==2.12.0->openrlhf==0.5.0) (0.4.1)
Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default]==2.12.0->openrlhf==0.5.0)
  Downloading uc_micro_py-1.0.3-py3-none-any.whl.metadata (2.0 kB)
Downloading ray-2.12.0-cp310-cp310-manylinux2014_x86_64.whl (65.3 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 65.3/65.3 MB 36.5 MB/s eta 0:00:00
Downloading transformers-4.46.1-py3-none-any.whl (10.0 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10.0/10.0 MB 37.0 MB/s eta 0:00:00
Downloading accelerate-1.3.0-py3-none-any.whl (336 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 336.6/336.6 kB 25.1 MB/s eta 0:00:00
Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 69.7/69.7 MB 35.1 MB/s eta 0:00:00
Downloading datasets-3.2.0-py3-none-any.whl (480 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 480.6/480.6 kB 25.2 MB/s eta 0:00:00
Downloading isort-6.0.0-py3-none-any.whl (94 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 94.1/94.1 kB 149.7 MB/s eta 0:00:00
Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)
Downloading loralib-0.1.2-py3-none-any.whl (10 kB)
Downloading optimum-1.24.0-py3-none-any.whl (433 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 433.6/433.6 kB 28.3 MB/s eta 0:00:00
Downloading peft-0.14.0-py3-none-any.whl (374 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 374.8/374.8 kB 50.2 MB/s eta 0:00:00
Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 927.3/927.3 kB 26.9 MB/s eta 0:00:00
Downloading wandb-0.19.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.9 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20.9/20.9 MB 36.8 MB/s eta 0:00:00
Downloading dill-0.3.8-py3-none-any.whl (116 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 116.3/116.3 kB 99.6 MB/s eta 0:00:00
Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)
Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 207.6/207.6 kB 24.7 MB/s eta 0:00:00
Downloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 464.1/464.1 kB 30.8 MB/s eta 0:00:00
Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 134.8/134.8 kB 27.9 MB/s eta 0:00:00
Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.7 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.7/2.7 MB 34.0 MB/s eta 0:00:00
Downloading pyarrow-19.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.1 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 42.1/42.1 MB 37.1 MB/s eta 0:00:00
Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 462.0/462.0 kB 33.2 MB/s eta 0:00:00
Downloading sentry_sdk-2.20.0-py2.py3-none-any.whl (322 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 322.6/322.6 kB 30.1 MB/s eta 0:00:00
Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.0/3.0 MB 33.1 MB/s eta 0:00:00
Downloading virtualenv-20.29.2-py3-none-any.whl (4.3 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.3/4.3 MB 33.2 MB/s eta 0:00:00
Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)
Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 201.4/201.4 kB 24.6 MB/s eta 0:00:00
Downloading hjson-3.1.0-py3-none-any.whl (54 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 54.0/54.0 kB 31.1 MB/s eta 0:00:00
Downloading memray-1.15.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (8.3 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 8.3/8.3 MB 32.7 MB/s eta 0:00:00
Downloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 44.4/44.4 kB 229.1 MB/s eta 0:00:00
Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 128.2/128.2 kB 23.1 MB/s eta 0:00:00
Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)
Downloading setproctitle-1.3.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)
Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 194.1/194.1 kB 22.6 MB/s eta 0:00:00
Downloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 469.0/469.0 kB 27.8 MB/s eta 0:00:00
Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 62.8/62.8 kB 19.9 MB/s eta 0:00:00
Downloading google_api_core-2.24.1-py3-none-any.whl (160 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 160.1/160.1 kB 23.0 MB/s eta 0:00:00
Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)
Downloading textual-1.0.0-py3-none-any.whl (660 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 660.5/660.5 kB 39.4 MB/s eta 0:00:00
Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 221.7/221.7 kB 24.8 MB/s eta 0:00:00
Downloading proto_plus-1.26.0-py3-none-any.whl (50 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 50.2/50.2 kB 211.9 MB/s eta 0:00:00
Downloading smmap-5.0.2-py3-none-any.whl (24 kB)
Downloading linkify_it_py-2.0.3-py3-none-any.whl (19 kB)
Downloading uc_micro_py-1.0.3-py3-none-any.whl (6.2 kB)
Building wheels for collected packages: openrlhf, deepspeed, flash-attn, transformers_stream_generator, word2number, zss
  Building editable for openrlhf (pyproject.toml): started
  Building editable for openrlhf (pyproject.toml): finished with status 'done'
  Created wheel for openrlhf: filename=openrlhf-0.5.0-0.editable-py3-none-any.whl size=9753 sha256=233052c2ad93d8fbee0e42176708ca23bc845cdc1702d9f849c7a07b65a9d65e
  Stored in directory: /tmp/pip-ephem-wheel-cache-0qzixu10/wheels/dc/6c/8d/2965fd3a9fbd2c9795221c5247dd05589758e834ff0668ae63
  Building wheel for deepspeed (setup.py): started
  Building wheel for deepspeed (setup.py): finished with status 'done'
  Created wheel for deepspeed: filename=deepspeed-0.15.0-py3-none-any.whl size=1483707 sha256=64544daacdc1f444e1f7829e5386062525f8d37101ba4cb7b6ba8fbb1031cd82
  Stored in directory: /tmp/pip-ephem-wheel-cache-0qzixu10/wheels/46/5a/dd/2f36986baec22867dab84e6176db30353ef54e7415cce5f2e0
  Building wheel for flash-attn (setup.py): started
  Building wheel for flash-attn (setup.py): finished with status 'done'
  Created wheel for flash-attn: filename=flash_attn-2.6.1-cp310-cp310-linux_x86_64.whl size=198469920 sha256=f60a6af22f14861a83dd8107698e876716f6b5a57458ce333dfdca27c04b5c6e
  Stored in directory: /tmp/pip-ephem-wheel-cache-0qzixu10/wheels/91/6a/38/f0faa036b4ac73a73247386f1ab1bb4cb4f6e72e6861a779f1
  Building wheel for transformers_stream_generator (setup.py): started
  Building wheel for transformers_stream_generator (setup.py): finished with status 'done'
  Created wheel for transformers_stream_generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12425 sha256=09489699a7be5f697c28cff8017fd47056763049ea14daf1b27e14ef4c5de52f
  Stored in directory: /tmp/pip-ephem-wheel-cache-0qzixu10/wheels/95/4a/90/140f7b67d125906f6a165f38aad212ecb4a695ad0d87582437
  Building wheel for word2number (setup.py): started
  Building wheel for word2number (setup.py): finished with status 'done'
  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5566 sha256=25225d15773ca51dc5e9a57e6baa11ac7bb770c8a46661a3a4b8e758899d3881
  Stored in directory: /tmp/pip-ephem-wheel-cache-0qzixu10/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b
  Building wheel for zss (setup.py): started
  Building wheel for zss (setup.py): finished with status 'done'
  Created wheel for zss: filename=zss-1.2.0-py3-none-any.whl size=6724 sha256=857913af764675c672760ac69ed06f2b97403afec26dd7cee3a8174d245f8695
  Stored in directory: /tmp/pip-ephem-wheel-cache-0qzixu10/wheels/f6/61/2a/cf33ab7301cc318a13418d9a805c1832be561b46e7d9337625
Successfully built openrlhf deepspeed flash-attn transformers_stream_generator word2number zss
Installing collected packages: word2number, py-spy, py-cpuinfo, opencensus-context, nvidia-ml-py, hjson, distlib, colorful, zss, xxhash, virtualenv, uc-micro-py, smmap, setproctitle, sentry-sdk, safetensors, pyarrow, proto-plus, loralib, jsonlines, isort, googleapis-common-protos, docker-pycreds, dill, multiprocess, linkify-it-py, huggingface-hub, gitdb, torchmetrics, tokenizers, google-api-core, gitpython, flash-attn, deepspeed, bitsandbytes, aiohttp-cors, accelerate, wandb, transformers, textual, ray, opencensus, datasets, transformers_stream_generator, peft, optimum, memray, openrlhf
  Attempting uninstall: pyarrow
    Found existing installation: pyarrow 14.0.2
    Uninstalling pyarrow-14.0.2:
      Successfully uninstalled pyarrow-14.0.2
  Attempting uninstall: flash-attn
    Found existing installation: flash-attn 2.4.2
    Uninstalling flash-attn-2.4.2:
      Successfully uninstalled flash-attn-2.4.2
Successfully installed accelerate-1.3.0 aiohttp-cors-0.7.0 bitsandbytes-0.45.2 colorful-0.5.6 datasets-3.2.0 deepspeed-0.15.0 dill-0.3.8 distlib-0.3.9 docker-pycreds-0.4.0 flash-attn-2.6.1 gitdb-4.0.12 gitpython-3.1.44 google-api-core-2.24.1 googleapis-common-protos-1.66.0 hjson-3.1.0 huggingface-hub-0.28.1 isort-6.0.0 jsonlines-4.0.0 linkify-it-py-2.0.3 loralib-0.1.2 memray-1.15.0 multiprocess-0.70.16 nvidia-ml-py-12.570.86 opencensus-0.11.4 opencensus-context-0.1.3 openrlhf-0.5.0 optimum-1.24.0 peft-0.14.0 proto-plus-1.26.0 py-cpuinfo-9.0.0 py-spy-0.4.0 pyarrow-19.0.0 ray-2.12.0 safetensors-0.5.2 sentry-sdk-2.20.0 setproctitle-1.3.4 smmap-5.0.2 textual-1.0.0 tokenizers-0.20.3 torchmetrics-1.6.1 transformers-4.46.1 transformers_stream_generator-0.0.5 uc-micro-py-1.0.3 virtualenv-20.29.2 wandb-0.19.6 word2number-1.1 xxhash-3.5.0 zss-1.2.0
/workspace/hdfs/model_hub
Number of examples in SWE-bench_oracle: 18817
Finished processing SWE-bench_oracle.
Number of examples that need import: 5803
Number of remain instances: 13014
2025-02-12 09:32:41,173	INFO usage_lib.py:469 -- Usage stats collection is enabled by default without user confirmation because this terminal is detected to be non-interactive. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.
2025-02-12 09:32:41,173	INFO scripts.py:764 -- [37mLocal node IP[39m: [1m0.0.0.0[22m
2025-02-12 09:32:44,373	SUCC scripts.py:801 -- [32m--------------------[39m
2025-02-12 09:32:44,373	SUCC scripts.py:802 -- [32mRay runtime started.[39m
2025-02-12 09:32:44,373	SUCC scripts.py:803 -- [32m--------------------[39m
2025-02-12 09:32:44,373	INFO scripts.py:805 -- [36mNext steps[39m
2025-02-12 09:32:44,373	INFO scripts.py:808 -- To add another node to this Ray cluster, run
2025-02-12 09:32:44,373	INFO scripts.py:811 -- [1m  ray start --address='0.0.0.0:6379'[22m
2025-02-12 09:32:44,373	INFO scripts.py:820 -- To connect to this Ray cluster:
2025-02-12 09:32:44,373	INFO scripts.py:822 -- [35mimport[39m[26m ray
2025-02-12 09:32:44,373	INFO scripts.py:823 -- ray[35m.[39m[26minit(_node_ip_address[35m=[39m[26m[33m'0.0.0.0'[39m[26m)
2025-02-12 09:32:44,373	INFO scripts.py:835 -- To submit a Ray job using the Ray Jobs CLI:
2025-02-12 09:32:44,373	INFO scripts.py:836 -- [1m  RAY_ADDRESS='http://127.0.0.1:8265' ray job submit --working-dir . -- python my_script.py[22m
2025-02-12 09:32:44,373	INFO scripts.py:845 -- See https://docs.ray.io/en/latest/cluster/running-applications/job-submission/index.html 
2025-02-12 09:32:44,373	INFO scripts.py:849 -- for more information on submitting Ray jobs to the Ray cluster.
2025-02-12 09:32:44,374	INFO scripts.py:854 -- To terminate the Ray runtime, run
2025-02-12 09:32:44,374	INFO scripts.py:855 -- [1m  ray stop[22m
2025-02-12 09:32:44,374	INFO scripts.py:858 -- To view the status of the cluster, use
2025-02-12 09:32:44,374	INFO scripts.py:859 --   [1mray status[22m[26m
2025-02-12 09:32:44,374	INFO scripts.py:863 -- To monitor and debug Ray, view the dashboard at 
2025-02-12 09:32:44,374	INFO scripts.py:864 --   [1m127.0.0.1:8265[22m[26m
2025-02-12 09:32:44,374	INFO scripts.py:871 -- [4mIf connection to the dashboard fails, check your firewall settings and network configuration.[24m
2025-02-12 09:32:45,310	INFO cli.py:36 -- [37mJob submission server address[39m: [1mhttp://127.0.0.1:8265[22m
2025-02-12 09:32:50,561	SUCC cli.py:60 -- [32m-------------------------------------------------------[39m
2025-02-12 09:32:50,561	SUCC cli.py:61 -- [32mJob 'raysubmit_6tGve3tEijPu73PT' submitted successfully[39m
2025-02-12 09:32:50,561	SUCC cli.py:62 -- [32m-------------------------------------------------------[39m
2025-02-12 09:32:50,561	INFO cli.py:286 -- [36mNext steps[39m
2025-02-12 09:32:50,561	INFO cli.py:287 -- Query the logs of the job:
2025-02-12 09:32:50,561	INFO cli.py:289 -- [1mray job logs raysubmit_6tGve3tEijPu73PT[22m
2025-02-12 09:32:50,561	INFO cli.py:291 -- Query the status of the job:
2025-02-12 09:32:50,561	INFO cli.py:293 -- [1mray job status raysubmit_6tGve3tEijPu73PT[22m
2025-02-12 09:32:50,561	INFO cli.py:295 -- Request the job to be stopped:
2025-02-12 09:32:50,561	INFO cli.py:297 -- [1mray job stop raysubmit_6tGve3tEijPu73PT[22m
2025-02-12 09:32:50,565	INFO cli.py:304 -- Tailing logs until the job exits (disable with --no-wait):
[2025-02-12 09:33:03,095] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
df: /root/.triton/autotune: No such file or directory
The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.

0it [00:00, ?it/s]
0it [00:00, ?it/s]
===============================
============ Finish configuring strategy ============
2025-02-12 09:33:07,534	INFO worker.py:1429 -- Using address 0.0.0.0:6379 set in the environment variable RAY_ADDRESS
2025-02-12 09:33:07,534	INFO worker.py:1564 -- Connecting to existing Ray cluster at address: 0.0.0.0:6379...
2025-02-12 09:33:07,548	INFO worker.py:1740 -- Connected to Ray cluster. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
============ Finish creating placement group ============
[36m(pid=3672)[0m [2025-02-12 09:33:11,620] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
============ Finish creating actor model ============
[36m(pid=3797)[0m [2025-02-12 09:33:19,725] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(pid=3799)[0m [2025-02-12 09:33:19,853] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
============ Finish creating reference model ============
============ Creating critic model ============
[36m(pid=4270)[0m [2025-02-12 09:33:27,483] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
============ Finish creating critic model ============
============ Init models ============
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:33:32,446] [INFO] [comm.py:652:init_distributed] cdb=None
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:33:32,446] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[36m(ActorModelRayActorBOX pid=3672)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorModelRayActorBOX pid=3672)[0m 
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  4.13it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m Actor(
[36m(ActorModelRayActorBOX pid=3672)[0m   (model): Qwen2ForCausalLM(
[36m(ActorModelRayActorBOX pid=3672)[0m     (model): Qwen2Model(
[36m(ActorModelRayActorBOX pid=3672)[0m       (embed_tokens): Embedding(152064, 3584)
[36m(ActorModelRayActorBOX pid=3672)[0m       (layers): ModuleList(
[36m(ActorModelRayActorBOX pid=3672)[0m         (0-27): 28 x Qwen2DecoderLayer(
[36m(ActorModelRayActorBOX pid=3672)[0m           (self_attn): Qwen2FlashAttention2(
[36m(ActorModelRayActorBOX pid=3672)[0m             (q_proj): Linear(in_features=3584, out_features=3584, bias=True)
[36m(ActorModelRayActorBOX pid=3672)[0m             (k_proj): Linear(in_features=3584, out_features=512, bias=True)
[36m(ActorModelRayActorBOX pid=3672)[0m             (v_proj): Linear(in_features=3584, out_features=512, bias=True)
[36m(ActorModelRayActorBOX pid=3672)[0m             (o_proj): Linear(in_features=3584, out_features=3584, bias=False)
[36m(ActorModelRayActorBOX pid=3672)[0m             (rotary_emb): Qwen2RotaryEmbedding()
[36m(ActorModelRayActorBOX pid=3672)[0m           )
[36m(ActorModelRayActorBOX pid=3672)[0m           (mlp): Qwen2MLP(
[36m(ActorModelRayActorBOX pid=3672)[0m             (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)
[36m(ActorModelRayActorBOX pid=3672)[0m             (up_proj): Linear(in_features=3584, out_features=18944, bias=False)
[36m(ActorModelRayActorBOX pid=3672)[0m             (down_proj): Linear(in_features=18944, out_features=3584, bias=False)
[36m(ActorModelRayActorBOX pid=3672)[0m             (act_fn): SiLU()
[36m(ActorModelRayActorBOX pid=3672)[0m           )
[36m(ActorModelRayActorBOX pid=3672)[0m           (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)
[36m(ActorModelRayActorBOX pid=3672)[0m           (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)
[36m(ActorModelRayActorBOX pid=3672)[0m         )
[36m(ActorModelRayActorBOX pid=3672)[0m       )
[36m(ActorModelRayActorBOX pid=3672)[0m       (norm): Qwen2RMSNorm((3584,), eps=1e-06)
[36m(ActorModelRayActorBOX pid=3672)[0m       (rotary_emb): Qwen2RotaryEmbedding()
[36m(ActorModelRayActorBOX pid=3672)[0m     )
[36m(ActorModelRayActorBOX pid=3672)[0m     (lm_head): Linear(in_features=3584, out_features=152064, bias=False)
[36m(ActorModelRayActorBOX pid=3672)[0m   )
[36m(ActorModelRayActorBOX pid=3672)[0m )
[36m(pid=4272)[0m [2025-02-12 09:33:27,887] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3672)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.32it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.29it/s]
[36m(ReferenceModelRayActor pid=4270)[0m [2025-02-12 09:33:33,101] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:33,128] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.15.0, git-hash=unknown, git-branch=unknown
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:33,128] [INFO] [comm.py:677:init_distributed] Distributed backend already initialized
[36m(ActorModelRayActorBOX pid=3672)[0m Using /root/.cache/torch_extensions/py310_cu125 as PyTorch extensions root...
[36m(ActorModelRayActorBOX pid=3672)[0m Creating extension directory /root/.cache/torch_extensions/py310_cu125/cpu_adam...
[36m(ActorModelRayActorBOX pid=3672)[0m Emitting ninja build file /root/.cache/torch_extensions/py310_cu125/cpu_adam/build.ninja...
[36m(ActorModelRayActorBOX pid=3672)[0m Building extension module cpu_adam...
[36m(ActorModelRayActorBOX pid=3672)[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,357] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,359] [INFO] [logging.py:96:log_dist] [Rank 0] Creating BF16 optimizer
[36m(ReferenceModelRayActor pid=4271)[0m [2025-02-12 09:33:32,452] [INFO] [comm.py:652:init_distributed] cdb=None[32m [repeated 7x across cluster][0m
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:32,444] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[36m(ReferenceModelRayActor pid=3800)[0m Actor(
[36m(ReferenceModelRayActor pid=3800)[0m     (model): Qwen2Model([32m [repeated 2x across cluster][0m
[36m(ReferenceModelRayActor pid=3800)[0m       (embed_tokens): Embedding(152064, 3584)
[36m(ReferenceModelRayActor pid=3800)[0m       (layers): ModuleList(
[36m(ReferenceModelRayActor pid=3800)[0m         (0-27): 28 x Qwen2DecoderLayer(
[36m(ReferenceModelRayActor pid=3800)[0m           (self_attn): Qwen2FlashAttention2(
[36m(ReferenceModelRayActor pid=3800)[0m             (q_proj): Linear(in_features=3584, out_features=3584, bias=True)
[36m(ReferenceModelRayActor pid=3800)[0m             (k_proj): Linear(in_features=3584, out_features=512, bias=True)
[36m(ReferenceModelRayActor pid=3800)[0m             (v_proj): Linear(in_features=3584, out_features=512, bias=True)
[36m(ReferenceModelRayActor pid=3800)[0m             (o_proj): Linear(in_features=3584, out_features=3584, bias=False)
[36m(ReferenceModelRayActor pid=3800)[0m       (rotary_emb): Qwen2RotaryEmbedding()[32m [repeated 2x across cluster][0m
[36m(ReferenceModelRayActor pid=3800)[0m )[32m [repeated 7x across cluster][0m
[36m(ReferenceModelRayActor pid=3800)[0m           (mlp): Qwen2MLP(
[36m(ReferenceModelRayActor pid=3800)[0m             (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)
[36m(ReferenceModelRayActor pid=3800)[0m             (up_proj): Linear(in_features=3584, out_features=18944, bias=False)
[36m(ReferenceModelRayActor pid=3800)[0m             (down_proj): Linear(in_features=18944, out_features=3584, bias=False)
[36m(ReferenceModelRayActor pid=3800)[0m             (act_fn): SiLU()
[36m(ReferenceModelRayActor pid=3800)[0m           (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)
[36m(ReferenceModelRayActor pid=3800)[0m           (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)
[36m(ReferenceModelRayActor pid=3800)[0m       (norm): Qwen2RMSNorm((3584,), eps=1e-06)
[36m(ReferenceModelRayActor pid=3800)[0m     (lm_head): Linear(in_features=3584, out_features=152064, bias=False)
[36m(pid=4747)[0m [2025-02-12 09:33:35,671] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)[32m [repeated 3x across cluster][0m
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:33,128] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4[32m [repeated 3x across cluster][0m
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,627] [INFO] [utils.py:781:see_memory_usage] begin bf16_optimizer
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,628] [INFO] [utils.py:782:see_memory_usage] MA 14.23 GB         Max_MA 14.23 GB         CA 14.35 GB         Max_CA 14 GB 
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,628] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 20.53 GB, percent = 4.1%
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,847] [INFO] [utils.py:781:see_memory_usage] end bf16_ optimizer
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,848] [INFO] [utils.py:782:see_memory_usage] MA 14.23 GB         Max_MA 14.23 GB         CA 14.35 GB         Max_CA 14 GB 
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,849] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 20.61 GB, percent = 4.1%
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,850] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,850] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
[36m(ReferenceModelRayActor pid=3800)[0m     "partition_activations": false, 
[36m(ReferenceModelRayActor pid=3800)[0m     "contiguous_memory_optimization": false, 
[36m(ReferenceModelRayActor pid=3800)[0m     "cpu_checkpointing": false, 
[36m(ReferenceModelRayActor pid=3800)[0m     "number_checkpoints": null, 
[36m(ReferenceModelRayActor pid=3800)[0m     "synchronize_checkpoint_boundary": false, 
[36m(ReferenceModelRayActor pid=3800)[0m     "profile": false
[36m(ReferenceModelRayActor pid=3800)[0m }
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,850] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,850] [INFO] [config.py:1003:print]   amp_enabled .................. False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,850] [INFO] [config.py:1003:print]   amp_params ................... False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,850] [INFO] [config.py:1003:print]   autotuning_config ............ {
[36m(ReferenceModelRayActor pid=3800)[0m     "enabled": false, 
[36m(ReferenceModelRayActor pid=3800)[0m     "start_step": null, 
[36m(ReferenceModelRayActor pid=3800)[0m     "end_step": null, 
[36m(ReferenceModelRayActor pid=3800)[0m     "metric_path": null, 
[36m(ReferenceModelRayActor pid=3800)[0m     "arg_mappings": null, 
[36m(ReferenceModelRayActor pid=3800)[0m     "metric": "throughput", 
[36m(ReferenceModelRayActor pid=3800)[0m     "model_info": null, 
[36m(ReferenceModelRayActor pid=3800)[0m     "results_dir": "autotuning_results", 
[36m(ReferenceModelRayActor pid=3800)[0m     "exps_dir": "autotuning_exps", 
[36m(ReferenceModelRayActor pid=3800)[0m     "overwrite": true, 
[36m(ReferenceModelRayActor pid=3800)[0m     "fast": true, 
[36m(ReferenceModelRayActor pid=3800)[0m     "start_profile_step": 3, 
[36m(ReferenceModelRayActor pid=3800)[0m     "end_profile_step": 5, 
[36m(ReferenceModelRayActor pid=3800)[0m     "tuner_type": "gridsearch", 
[36m(ReferenceModelRayActor pid=3800)[0m     "tuner_early_stopping": 5, 
[36m(ReferenceModelRayActor pid=3800)[0m     "tuner_num_trials": 50, 
[36m(ReferenceModelRayActor pid=3800)[0m     "model_info_path": null, 
[36m(ReferenceModelRayActor pid=3800)[0m     "mp_size": 1, 
[36m(ReferenceModelRayActor pid=3800)[0m     "max_train_batch_size": null, 
[36m(ReferenceModelRayActor pid=3800)[0m     "min_train_batch_size": 1, 
[36m(ReferenceModelRayActor pid=3800)[0m     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[36m(ReferenceModelRayActor pid=3800)[0m     "min_train_micro_batch_size_per_gpu": 1, 
[36m(ReferenceModelRayActor pid=3800)[0m     "num_tuning_micro_batch_sizes": 3
[36m(ReferenceModelRayActor pid=3800)[0m }
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,850] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f65ac1b9cf0>
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   communication_data_type ...... None
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   disable_allgather ............ False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   dump_state ................... False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
[36m(ReferenceModelRayActor pid=3800)[0m     "enabled": false, 
[36m(ReferenceModelRayActor pid=3800)[0m     "recompute_fwd_factor": 0.0, 
[36m(ReferenceModelRayActor pid=3800)[0m     "profile_step": 1, 
[36m(ReferenceModelRayActor pid=3800)[0m     "module_depth": -1, 
[36m(ReferenceModelRayActor pid=3800)[0m     "top_modules": 1, 
[36m(ReferenceModelRayActor pid=3800)[0m     "detailed": true, 
[36m(ReferenceModelRayActor pid=3800)[0m     "output_file": null
[36m(ReferenceModelRayActor pid=3800)[0m }
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   global_rank .................. 0
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,851] [INFO] [config.py:1003:print]   grad_accum_dtype ............. None
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 16
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   gradient_clipping ............ 1.0
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   nebula_config ................ {
[36m(ReferenceModelRayActor pid=3800)[0m     "enabled": false, 
[36m(ReferenceModelRayActor pid=3800)[0m     "persistent_storage_path": null, 
[36m(ReferenceModelRayActor pid=3800)[0m     "persistent_time_interval": 100, 
[36m(ReferenceModelRayActor pid=3800)[0m     "num_of_version_in_retention": 2, 
[36m(ReferenceModelRayActor pid=3800)[0m     "enable_nebula_load": true, 
[36m(ReferenceModelRayActor pid=3800)[0m     "load_path": null
[36m(ReferenceModelRayActor pid=3800)[0m }
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   optimizer_name ............... None
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   optimizer_params ............. None
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   pld_enabled .................. False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   pld_params ................... False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   scheduler_name ............... None
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   scheduler_params ............. None
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   sparse_attention ............. None
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   steps_per_print .............. 100
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,852] [INFO] [config.py:1003:print]   train_batch_size ............. 128
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,853] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  2
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,853] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,853] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,853] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,853] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,853] [INFO] [config.py:1003:print]   world_size ................... 4
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,853] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,853] [INFO] [config.py:1003:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=True) offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,853] [INFO] [config.py:1003:print]   zero_enabled ................. False
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,853] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,853] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 0
[36m(ReferenceModelRayActor pid=3800)[0m [2025-02-12 09:33:40,853] [INFO] [config.py:989:print_user_config]   json = {
[36m(ReferenceModelRayActor pid=3800)[0m     "steps_per_print": 100, 
[36m(ReferenceModelRayActor pid=3800)[0m     "zero_optimization": {
[36m(ReferenceModelRayActor pid=3800)[0m         "stage": 0, 
[36m(ReferenceModelRayActor pid=3800)[0m         "stage3_param_persistence_threshold": "auto", 
[36m(ReferenceModelRayActor pid=3800)[0m         "offload_param": {
[36m(ReferenceModelRayActor pid=3800)[0m             "device": "none", 
[36m(ReferenceModelRayActor pid=3800)[0m             "pin_memory": true
[36m(ReferenceModelRayActor pid=3800)[0m         }
[36m(ReferenceModelRayActor pid=3800)[0m     }, 
[36m(ReferenceModelRayActor pid=3800)[0m     "bf16": {
[36m(ReferenceModelRayActor pid=3800)[0m         "enabled": true
[36m(ReferenceModelRayActor pid=3800)[0m     }, 
[36m(ReferenceModelRayActor pid=3800)[0m     "gradient_clipping": 1.0, 
[36m(ReferenceModelRayActor pid=3800)[0m     "prescale_gradients": false, 
[36m(ReferenceModelRayActor pid=3800)[0m     "wall_clock_breakdown": false, 
[36m(ReferenceModelRayActor pid=3800)[0m     "train_micro_batch_size_per_gpu": 2, 
[36m(ReferenceModelRayActor pid=3800)[0m     "train_batch_size": 128
[36m(ReferenceModelRayActor pid=3800)[0m }
[36m(ActorModelRayActorBOX pid=3672)[0m [1/3] c++ -MMD -MF cpu_adam.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -I/usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/includes -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.10/dist-packages/torch/include/THC -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/usr/local/cuda/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX256__ -D__ENABLE_CUDA__ -DBF16_AVAILABLE -c /usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/adam/cpu_adam.cpp -o cpu_adam.o 
[36m(ActorModelRayActorBOX pid=3672)[0m [2/3] c++ -MMD -MF cpu_adam_impl.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -I/usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/includes -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.10/dist-packages/torch/include/THC -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/usr/local/cuda/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX256__ -D__ENABLE_CUDA__ -DBF16_AVAILABLE -c /usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/adam/cpu_adam_impl.cpp -o cpu_adam_impl.o 
[36m(ActorModelRayActorBOX pid=3672)[0m [3/3] c++ cpu_adam.o cpu_adam_impl.o -shared -lcurand -L/usr/local/cuda/lib64 -L/usr/local/lib/python3.10/dist-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o cpu_adam.so
[36m(ActorModelRayActorBOX pid=3672)[0m Time to load cpu_adam op: 28.16741442680359 seconds
[36m(ActorModelRayActorBOX pid=3672)[0m dataset: data/swebench_oracle.json
[36m(ActorModelRayActorBOX pid=3672)[0m Loading extension module cpu_adam...
[36m(ReferenceModelRayActor pid=4271)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
[36m(ReferenceModelRayActor pid=4271)[0m 
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s][32m [repeated 7x across cluster][0m
[36m(ReferenceModelRayActor pid=4271)[0m 
Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  3.95it/s][32m [repeated 7x across cluster][0m
[36m(ActorModelRayActorBOX pid=3798)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.54it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.51it/s][32m [repeated 7x across cluster][0m
[36m(ActorModelRayActorBOX pid=3799)[0m Using /root/.cache/torch_extensions/py310_cu125 as PyTorch extensions root...[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 0 examples [00:00, ? examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 172 examples [00:00, 1249.37 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 341 examples [00:00, 1237.93 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 513 examples [00:00, 1292.69 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 683 examples [00:00, 1306.92 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 869 examples [00:00, 1403.79 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 1024 examples [00:00, 1376.01 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 1221 examples [00:00, 1431.58 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 1378 examples [00:01, 1386.25 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 1531 examples [00:01, 1308.16 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 1678 examples [00:01, 1289.85 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 1847 examples [00:01, 1322.76 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 2026 examples [00:01, 1363.33 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 2190 examples [00:01, 1348.69 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 2354 examples [00:01, 1323.95 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 2527 examples [00:01, 1350.25 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 2705 examples [00:01, 1416.03 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 2895 examples [00:02, 1472.01 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 3057 examples [00:02, 1436.13 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 3218 examples [00:02, 1403.57 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 3427 examples [00:02, 1512.98 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 3599 examples [00:02, 1482.26 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 3783 examples [00:02, 1475.09 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 4000 examples [00:02, 1368.35 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 4169 examples [00:03, 1352.66 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 4330 examples [00:03, 1316.16 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 4472 examples [00:03, 1284.85 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 4623 examples [00:03, 1273.42 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 4781 examples [00:03, 1250.74 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 4949 examples [00:03, 1304.89 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 5123 examples [00:03, 1328.15 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 5298 examples [00:03, 1350.86 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 5454 examples [00:04, 1061.25 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 5638 examples [00:04, 1201.06 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 5836 examples [00:04, 1332.73 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 6019 examples [00:04, 1398.28 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 6190 examples [00:04, 1397.03 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 6341 examples [00:04, 1359.50 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 6503 examples [00:04, 1364.77 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m Loading extension module cpu_adam...[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 6702 examples [00:04, 1446.11 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 6872 examples [00:05, 1427.29 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 7036 examples [00:05, 1374.08 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 7231 examples [00:05, 1268.33 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 7400 examples [00:05, 1314.55 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 7574 examples [00:05, 1343.07 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 7749 examples [00:05, 1368.79 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 7916 examples [00:05, 1364.14 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 8148 examples [00:06, 1360.02 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 8333 examples [00:06, 1409.53 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 8487 examples [00:06, 1393.31 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 8676 examples [00:06, 1280.03 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 8863 examples [00:06, 1350.21 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 9014 examples [00:06, 1340.17 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 9208 examples [00:06, 1466.01 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 9373 examples [00:06, 1447.77 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 9571 examples [00:07, 1550.45 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 9765 examples [00:07, 1597.52 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 9977 examples [00:07, 1455.70 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 10134 examples [00:07, 1386.85 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 10315 examples [00:07, 1425.66 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 10531 examples [00:07, 1360.32 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 10730 examples [00:07, 1428.88 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 10878 examples [00:07, 1401.48 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 11036 examples [00:08, 1358.44 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 11180 examples [00:08, 1340.47 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 11383 examples [00:08, 1455.91 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 11556 examples [00:08, 1421.33 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 11725 examples [00:08, 1451.94 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 11903 examples [00:08, 1497.91 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 12058 examples [00:08, 1431.84 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 12237 examples [00:08, 1423.93 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 12406 examples [00:09, 1422.14 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 12612 examples [00:09, 1495.24 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 12777 examples [00:09, 1461.34 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 12959 examples [00:09, 1465.47 examples/s]
[36m(ActorModelRayActorBOX pid=3799)[0m 
Generating train split: 13014 examples [00:09, 1381.27 examples/s]
[36m(ActorModelRayActorBOX pid=3672)[0m loaded data/swebench_oracle.json with data_files=data/swebench_oracle.json
[36m(ActorModelRayActorBOX pid=3672)[0m [Dataset({
[36m(ActorModelRayActorBOX pid=3672)[0m     features: ['instance_id', 'input', 'ground_truth_answer', 'answer', 'target', 'commit'],
[36m(ActorModelRayActorBOX pid=3672)[0m     num_rows: 13014
[36m(ActorModelRayActorBOX pid=3672)[0m })]
[36m(ActorModelRayActorBOX pid=3797)[0m Time to load cpu_adam op: 28.14832878112793 seconds[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:   0%|          | 0/13014 [00:00<?, ?it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:   4%|â–         | 558/13014 [00:00<00:02, 5571.41it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:   9%|â–Š         | 1116/13014 [00:00<00:02, 5057.92it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  12%|â–ˆâ–        | 1625/13014 [00:00<00:02, 4943.67it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  16%|â–ˆâ–‹        | 2121/13014 [00:00<00:02, 4913.87it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  20%|â–ˆâ–ˆ        | 2614/13014 [00:00<00:02, 4643.01it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  24%|â–ˆâ–ˆâ–       | 3108/13014 [00:00<00:02, 4734.54it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  28%|â–ˆâ–ˆâ–Š       | 3648/13014 [00:00<00:01, 4916.25it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  32%|â–ˆâ–ˆâ–ˆâ–      | 4142/13014 [00:00<00:01, 4915.09it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 4635/13014 [00:00<00:01, 4784.90it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 5117/13014 [00:01<00:01, 4780.79it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5597/13014 [00:01<00:01, 4757.64it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 6107/13014 [00:01<00:01, 4851.13it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6593/13014 [00:01<00:01, 4843.54it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7078/13014 [00:01<00:01, 4786.56it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7571/13014 [00:01<00:01, 4819.59it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8054/13014 [00:01<00:01, 4706.38it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 8555/13014 [00:01<00:00, 4793.55it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9063/13014 [00:01<00:00, 4869.11it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 9591/13014 [00:01<00:00, 4990.57it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 10091/13014 [00:02<00:00, 4794.38it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 10573/13014 [00:02<00:00, 4797.38it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11055/13014 [00:02<00:00, 4774.15it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 11580/13014 [00:02<00:00, 4913.53it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12073/13014 [00:02<00:00, 4736.55it/s]
[36m(ActorModelRayActorBOX pid=3672)[0m 
Preprocessing data:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 12617/13014 [00:02<00:00, 4937.83it/s]
Preprocessing data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13014/13014 [00:02<00:00, 4858.86it/s]
[36m(ActorModelRayActorBOX pid=3799)[0m [2025-02-12 09:34:15,654] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:15,792] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.15.0, git-hash=unknown, git-branch=unknown
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:15,792] [INFO] [comm.py:677:init_distributed] Distributed backend already initialized
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:20,883] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:20,885] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:20,885] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:20,897] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:20,897] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:20,898] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:20,898] [INFO] [stage_1_and_2.py:148:__init__] Reduce bucket size 500000000
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:20,898] [INFO] [stage_1_and_2.py:149:__init__] Allgather bucket size 500000000
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:20,898] [INFO] [stage_1_and_2.py:150:__init__] CPU Offload: True
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:20,898] [INFO] [stage_1_and_2.py:151:__init__] Round robin gradient partitioning: False
[36m(ActorModelRayActorBOX pid=3797)[0m [2025-02-12 09:34:15,767] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:39,058] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:39,059] [INFO] [utils.py:782:see_memory_usage] MA 15.2 GB         Max_MA 15.2 GB         CA 15.2 GB         Max_CA 15 GB 
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:39,059] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 78.51 GB, percent = 15.6%
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,039] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,040] [INFO] [utils.py:782:see_memory_usage] MA 15.2 GB         Max_MA 15.2 GB         CA 15.2 GB         Max_CA 15 GB 
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,040] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 127.58 GB, percent = 25.3%
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,040] [INFO] [stage_1_and_2.py:543:__init__] optimizer state initialized
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,235] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,236] [INFO] [utils.py:782:see_memory_usage] MA 15.2 GB         Max_MA 15.2 GB         CA 15.2 GB         Max_CA 15 GB 
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,236] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 128.42 GB, percent = 25.5%
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,239] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,239] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,239] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7f3eeb4339a0>
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,239] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,240] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,240] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
[36m(ActorModelRayActorBOX pid=3672)[0m     "partition_activations": false, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "contiguous_memory_optimization": false, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "cpu_checkpointing": false, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "number_checkpoints": null, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "synchronize_checkpoint_boundary": false, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "profile": false
[36m(ActorModelRayActorBOX pid=3672)[0m }
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,240] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,240] [INFO] [config.py:1003:print]   amp_enabled .................. False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,240] [INFO] [config.py:1003:print]   amp_params ................... False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   autotuning_config ............ {
[36m(ActorModelRayActorBOX pid=3672)[0m     "enabled": false, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "start_step": null, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "end_step": null, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "metric_path": null, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "arg_mappings": null, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "metric": "throughput", 
[36m(ActorModelRayActorBOX pid=3672)[0m     "model_info": null, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "results_dir": "autotuning_results", 
[36m(ActorModelRayActorBOX pid=3672)[0m     "exps_dir": "autotuning_exps", 
[36m(ActorModelRayActorBOX pid=3672)[0m     "overwrite": true, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "fast": true, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "start_profile_step": 3, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "end_profile_step": 5, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "tuner_type": "gridsearch", 
[36m(ActorModelRayActorBOX pid=3672)[0m     "tuner_early_stopping": 5, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "tuner_num_trials": 50, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "model_info_path": null, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "mp_size": 1, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "max_train_batch_size": null, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "min_train_batch_size": 1, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "min_train_micro_batch_size_per_gpu": 1, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "num_tuning_micro_batch_sizes": 3
[36m(ActorModelRayActorBOX pid=3672)[0m }
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f3ed7d33700>
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   communication_data_type ...... None
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   disable_allgather ............ False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   dump_state ................... False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
[36m(ActorModelRayActorBOX pid=3672)[0m     "enabled": false, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "recompute_fwd_factor": 0.0, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "profile_step": 1, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "module_depth": -1, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "top_modules": 1, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "detailed": true, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "output_file": null
[36m(ActorModelRayActorBOX pid=3672)[0m }
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   global_rank .................. 0
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,241] [INFO] [config.py:1003:print]   grad_accum_dtype ............. fp32
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 16
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   gradient_clipping ............ 1.0
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   nebula_config ................ {
[36m(ActorModelRayActorBOX pid=3672)[0m     "enabled": false, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "persistent_storage_path": null, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "persistent_time_interval": 100, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "num_of_version_in_retention": 2, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "enable_nebula_load": true, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "load_path": null
[36m(ActorModelRayActorBOX pid=3672)[0m }
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   optimizer_name ............... None
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   optimizer_params ............. None
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   pld_enabled .................. False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   pld_params ................... False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   scheduler_name ............... None
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   scheduler_params ............. None
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   sparse_attention ............. None
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   steps_per_print .............. 100
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   train_batch_size ............. 128
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  2
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,242] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,243] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,243] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,243] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,243] [INFO] [config.py:1003:print]   world_size ................... 4
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,243] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,243] [INFO] [config.py:1003:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,243] [INFO] [config.py:1003:print]   zero_enabled ................. True
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,243] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,243] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 2
[36m(ActorModelRayActorBOX pid=3672)[0m [2025-02-12 09:34:47,243] [INFO] [config.py:989:print_user_config]   json = {
[36m(ActorModelRayActorBOX pid=3672)[0m     "steps_per_print": 100, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "zero_optimization": {
[36m(ActorModelRayActorBOX pid=3672)[0m         "stage": 2, 
[36m(ActorModelRayActorBOX pid=3672)[0m         "offload_param": {
[36m(ActorModelRayActorBOX pid=3672)[0m             "device": "none"
[36m(ActorModelRayActorBOX pid=3672)[0m         }, 
[36m(ActorModelRayActorBOX pid=3672)[0m         "offload_optimizer": {
[36m(ActorModelRayActorBOX pid=3672)[0m             "device": "cpu", 
[36m(ActorModelRayActorBOX pid=3672)[0m             "pin_memory": true
[36m(ActorModelRayActorBOX pid=3672)[0m         }, 
[36m(ActorModelRayActorBOX pid=3672)[0m         "sub_group_size": "auto", 
[36m(ActorModelRayActorBOX pid=3672)[0m         "stage3_max_live_parameters": "auto", 
[36m(ActorModelRayActorBOX pid=3672)[0m         "stage3_max_reuse_distance": "auto", 
[36m(ActorModelRayActorBOX pid=3672)[0m         "stage3_param_persistence_threshold": "auto", 
[36m(ActorModelRayActorBOX pid=3672)[0m         "stage3_prefetch_bucket_size": "auto", 
[36m(ActorModelRayActorBOX pid=3672)[0m         "reduce_bucket_size": "auto", 
[36m(ActorModelRayActorBOX pid=3672)[0m         "zero_hpz_partition_size": 1, 
[36m(ActorModelRayActorBOX pid=3672)[0m         "zero_quantized_weights": false, 
[36m(ActorModelRayActorBOX pid=3672)[0m         "zero_quantized_gradients": false
[36m(ActorModelRayActorBOX pid=3672)[0m     }, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "bf16": {
[36m(ActorModelRayActorBOX pid=3672)[0m         "enabled": true
[36m(ActorModelRayActorBOX pid=3672)[0m     }, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "gradient_clipping": 1.0, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "prescale_gradients": false, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "wall_clock_breakdown": false, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "data_types": {
[36m(ActorModelRayActorBOX pid=3672)[0m         "grad_accum_dtype": "fp32"
[36m(ActorModelRayActorBOX pid=3672)[0m     }, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "train_micro_batch_size_per_gpu": 2, 
[36m(ActorModelRayActorBOX pid=3672)[0m     "train_batch_size": 128
[36m(ActorModelRayActorBOX pid=3672)[0m }
============ Finish init vLLM ============
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:34:50,261] [INFO] [comm.py:652:init_distributed] cdb=None
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:34:50,261] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[36m(CriticModelRayActor pid=4272)[0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[36m(CriticModelRayActor pid=4747)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(CriticModelRayActor pid=4272)[0m 
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
[36m(CriticModelRayActor pid=4758)[0m 
Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  3.99it/s]
[36m(CriticModelRayActor pid=4758)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.43it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.36it/s]
[36m(CriticModelRayActor pid=4758)[0m Some weights of CriticModel were not initialized from the model checkpoint at /workspace/hdfs/model_hub and are newly initialized: ['value_head.weight']
[36m(CriticModelRayActor pid=4758)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(CriticModelRayActor pid=4272)[0m CriticModel(
[36m(CriticModelRayActor pid=4272)[0m   (model): Qwen2Model(
[36m(CriticModelRayActor pid=4272)[0m     (embed_tokens): Embedding(152064, 3584)
[36m(CriticModelRayActor pid=4272)[0m     (layers): ModuleList(
[36m(CriticModelRayActor pid=4272)[0m       (0-27): 28 x Qwen2DecoderLayer(
[36m(CriticModelRayActor pid=4272)[0m         (self_attn): Qwen2FlashAttention2(
[36m(CriticModelRayActor pid=4272)[0m           (q_proj): Linear(in_features=3584, out_features=3584, bias=True)
[36m(CriticModelRayActor pid=4272)[0m           (k_proj): Linear(in_features=3584, out_features=512, bias=True)
[36m(CriticModelRayActor pid=4272)[0m           (v_proj): Linear(in_features=3584, out_features=512, bias=True)
[36m(CriticModelRayActor pid=4272)[0m           (o_proj): Linear(in_features=3584, out_features=3584, bias=False)
[36m(CriticModelRayActor pid=4272)[0m           (rotary_emb): Qwen2RotaryEmbedding()
[36m(CriticModelRayActor pid=4272)[0m         )
[36m(CriticModelRayActor pid=4272)[0m         (mlp): Qwen2MLP(
[36m(CriticModelRayActor pid=4272)[0m           (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)
[36m(CriticModelRayActor pid=4272)[0m           (up_proj): Linear(in_features=3584, out_features=18944, bias=False)
[36m(CriticModelRayActor pid=4272)[0m           (down_proj): Linear(in_features=18944, out_features=3584, bias=False)
[36m(CriticModelRayActor pid=4272)[0m           (act_fn): SiLU()
[36m(CriticModelRayActor pid=4272)[0m         )
[36m(CriticModelRayActor pid=4272)[0m         (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)
[36m(CriticModelRayActor pid=4272)[0m         (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)
[36m(CriticModelRayActor pid=4272)[0m       )
[36m(CriticModelRayActor pid=4272)[0m     )
[36m(CriticModelRayActor pid=4272)[0m     (norm): Qwen2RMSNorm((3584,), eps=1e-06)
[36m(CriticModelRayActor pid=4272)[0m     (rotary_emb): Qwen2RotaryEmbedding()
[36m(CriticModelRayActor pid=4272)[0m   )
[36m(CriticModelRayActor pid=4272)[0m   (value_head): Linear(in_features=3584, out_features=1, bias=False)
[36m(CriticModelRayActor pid=4272)[0m )
[36m(CriticModelRayActor pid=4272)[0m reward normalization status: True
[36m(CriticModelRayActor pid=4272)[0m mean: tensor([0.], dtype=torch.bfloat16), std tensor([1.], dtype=torch.bfloat16)
[36m(CriticModelRayActor pid=4758)[0m Using /root/.cache/torch_extensions/py310_cu125 as PyTorch extensions root...
[36m(CriticModelRayActor pid=4758)[0m Emitting ninja build file /root/.cache/torch_extensions/py310_cu125/cpu_adam/build.ninja...
[36m(CriticModelRayActor pid=4758)[0m Building extension module cpu_adam...
[36m(CriticModelRayActor pid=4758)[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[36m(CriticModelRayActor pid=4758)[0m Loading extension module cpu_adam...
[36m(CriticModelRayActor pid=4758)[0m ninja: no work to do.
[36m(CriticModelRayActor pid=4758)[0m Time to load cpu_adam op: 2.648519992828369 seconds
[36m(CriticModelRayActor pid=4758)[0m [2025-02-12 09:34:54,743] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:34:54,820] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.15.0, git-hash=unknown, git-branch=unknown
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:34:54,821] [INFO] [comm.py:677:init_distributed] Distributed backend already initialized
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:02,172] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:02,174] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:02,174] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[36m(CriticModelRayActor pid=4758)[0m [2025-02-12 09:34:50,264] [INFO] [comm.py:652:init_distributed] cdb=None[32m [repeated 3x across cluster][0m
[36m(CriticModelRayActor pid=4761)[0m Time to load cpu_adam op: 2.665863037109375 seconds[32m [repeated 3x across cluster][0m
[36m(CriticModelRayActor pid=4761)[0m [2025-02-12 09:34:54,819] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4[32m [repeated 3x across cluster][0m
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:02,187] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:02,187] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:02,187] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:02,187] [INFO] [stage_1_and_2.py:148:__init__] Reduce bucket size 500000000
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:02,188] [INFO] [stage_1_and_2.py:149:__init__] Allgather bucket size 500000000
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:02,188] [INFO] [stage_1_and_2.py:150:__init__] CPU Offload: True
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:02,188] [INFO] [stage_1_and_2.py:151:__init__] Round robin gradient partitioning: False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:21,379] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:21,379] [INFO] [utils.py:782:see_memory_usage] MA 14.19 GB         Max_MA 14.19 GB         CA 14.19 GB         Max_CA 14 GB 
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:21,380] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 162.51 GB, percent = 32.3%
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:30,875] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:30,876] [INFO] [utils.py:782:see_memory_usage] MA 14.19 GB         Max_MA 14.19 GB         CA 14.19 GB         Max_CA 14 GB 
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:30,877] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 188.44 GB, percent = 37.4%
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:30,877] [INFO] [stage_1_and_2.py:543:__init__] optimizer state initialized
============ Start training ============
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,080] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,081] [INFO] [utils.py:782:see_memory_usage] MA 14.19 GB         Max_MA 14.19 GB         CA 14.19 GB         Max_CA 14 GB 
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,081] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 188.44 GB, percent = 37.4%
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,084] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,084] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,084] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7f5f3763fd00>
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,084] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,085] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,086] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
[36m(CriticModelRayActor pid=4272)[0m     "partition_activations": false, 
[36m(CriticModelRayActor pid=4272)[0m     "contiguous_memory_optimization": false, 
[36m(CriticModelRayActor pid=4272)[0m     "cpu_checkpointing": false, 
[36m(CriticModelRayActor pid=4272)[0m     "number_checkpoints": null, 
[36m(CriticModelRayActor pid=4272)[0m     "synchronize_checkpoint_boundary": false, 
[36m(CriticModelRayActor pid=4272)[0m     "profile": false
[36m(CriticModelRayActor pid=4272)[0m }
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,086] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,086] [INFO] [config.py:1003:print]   amp_enabled .................. False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,086] [INFO] [config.py:1003:print]   amp_params ................... False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,086] [INFO] [config.py:1003:print]   autotuning_config ............ {
[36m(CriticModelRayActor pid=4272)[0m     "enabled": false, 
[36m(CriticModelRayActor pid=4272)[0m     "start_step": null, 
[36m(CriticModelRayActor pid=4272)[0m     "end_step": null, 
[36m(CriticModelRayActor pid=4272)[0m     "metric_path": null, 
[36m(CriticModelRayActor pid=4272)[0m     "arg_mappings": null, 
[36m(CriticModelRayActor pid=4272)[0m     "metric": "throughput", 
[36m(CriticModelRayActor pid=4272)[0m     "model_info": null, 
[36m(CriticModelRayActor pid=4272)[0m     "results_dir": "autotuning_results", 
[36m(CriticModelRayActor pid=4272)[0m     "exps_dir": "autotuning_exps", 
[36m(CriticModelRayActor pid=4272)[0m     "overwrite": true, 
[36m(CriticModelRayActor pid=4272)[0m     "fast": true, 
[36m(CriticModelRayActor pid=4272)[0m     "start_profile_step": 3, 
[36m(CriticModelRayActor pid=4272)[0m     "end_profile_step": 5, 
[36m(CriticModelRayActor pid=4272)[0m     "tuner_type": "gridsearch", 
[36m(CriticModelRayActor pid=4272)[0m     "tuner_early_stopping": 5, 
[36m(CriticModelRayActor pid=4272)[0m     "tuner_num_trials": 50, 
[36m(CriticModelRayActor pid=4272)[0m     "model_info_path": null, 
[36m(CriticModelRayActor pid=4272)[0m     "mp_size": 1, 
[36m(CriticModelRayActor pid=4272)[0m     "max_train_batch_size": null, 
[36m(CriticModelRayActor pid=4272)[0m     "min_train_batch_size": 1, 
[36m(CriticModelRayActor pid=4272)[0m     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[36m(CriticModelRayActor pid=4272)[0m     "min_train_micro_batch_size_per_gpu": 1, 
[36m(CriticModelRayActor pid=4272)[0m     "num_tuning_micro_batch_sizes": 3
[36m(CriticModelRayActor pid=4272)[0m }
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,086] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,086] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,086] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,086] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,086] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,086] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f5f341768c0>
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,086] [INFO] [config.py:1003:print]   communication_data_type ...... None
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,086] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,086] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,086] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,086] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,086] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,086] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,086] [INFO] [config.py:1003:print]   disable_allgather ............ False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,086] [INFO] [config.py:1003:print]   dump_state ................... False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,086] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
[36m(CriticModelRayActor pid=4272)[0m     "enabled": false, 
[36m(CriticModelRayActor pid=4272)[0m     "recompute_fwd_factor": 0.0, 
[36m(CriticModelRayActor pid=4272)[0m     "profile_step": 1, 
[36m(CriticModelRayActor pid=4272)[0m     "module_depth": -1, 
[36m(CriticModelRayActor pid=4272)[0m     "top_modules": 1, 
[36m(CriticModelRayActor pid=4272)[0m     "detailed": true, 
[36m(CriticModelRayActor pid=4272)[0m     "output_file": null
[36m(CriticModelRayActor pid=4272)[0m }
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   global_rank .................. 0
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   grad_accum_dtype ............. fp32
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 16
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   gradient_clipping ............ 1.0
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   nebula_config ................ {
[36m(CriticModelRayActor pid=4272)[0m     "enabled": false, 
[36m(CriticModelRayActor pid=4272)[0m     "persistent_storage_path": null, 
[36m(CriticModelRayActor pid=4272)[0m     "persistent_time_interval": 100, 
[36m(CriticModelRayActor pid=4272)[0m     "num_of_version_in_retention": 2, 
[36m(CriticModelRayActor pid=4272)[0m     "enable_nebula_load": true, 
[36m(CriticModelRayActor pid=4272)[0m     "load_path": null
[36m(CriticModelRayActor pid=4272)[0m }
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,087] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   optimizer_name ............... None
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   optimizer_params ............. None
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   pld_enabled .................. False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   pld_params ................... False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   scheduler_name ............... None
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   scheduler_params ............. None
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   sparse_attention ............. None
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   steps_per_print .............. 100
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   train_batch_size ............. 128
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  2
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   world_size ................... 4
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   zero_enabled ................. True
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 2
[36m(CriticModelRayActor pid=4272)[0m [2025-02-12 09:35:31,088] [INFO] [config.py:989:print_user_config]   json = {
[36m(CriticModelRayActor pid=4272)[0m     "steps_per_print": 100, 
[36m(CriticModelRayActor pid=4272)[0m     "zero_optimization": {
[36m(CriticModelRayActor pid=4272)[0m         "stage": 2, 
[36m(CriticModelRayActor pid=4272)[0m         "offload_param": {
[36m(CriticModelRayActor pid=4272)[0m             "device": "none"
[36m(CriticModelRayActor pid=4272)[0m         }, 
[36m(CriticModelRayActor pid=4272)[0m         "offload_optimizer": {
[36m(CriticModelRayActor pid=4272)[0m             "device": "cpu", 
[36m(CriticModelRayActor pid=4272)[0m             "pin_memory": true
[36m(CriticModelRayActor pid=4272)[0m         }, 
[36m(CriticModelRayActor pid=4272)[0m         "sub_group_size": "auto", 
[36m(CriticModelRayActor pid=4272)[0m         "stage3_max_live_parameters": "auto", 
[36m(CriticModelRayActor pid=4272)[0m         "stage3_max_reuse_distance": "auto", 
[36m(CriticModelRayActor pid=4272)[0m         "stage3_param_persistence_threshold": "auto", 
[36m(CriticModelRayActor pid=4272)[0m         "stage3_prefetch_bucket_size": "auto", 
[36m(CriticModelRayActor pid=4272)[0m         "reduce_bucket_size": "auto", 
[36m(CriticModelRayActor pid=4272)[0m         "zero_hpz_partition_size": 1, 
[36m(CriticModelRayActor pid=4272)[0m         "zero_quantized_weights": false, 
[36m(CriticModelRayActor pid=4272)[0m         "zero_quantized_gradients": false
[36m(CriticModelRayActor pid=4272)[0m     }, 
[36m(CriticModelRayActor pid=4272)[0m     "bf16": {
[36m(CriticModelRayActor pid=4272)[0m         "enabled": true
[36m(CriticModelRayActor pid=4272)[0m     }, 
[36m(CriticModelRayActor pid=4272)[0m     "gradient_clipping": 1.0, 
[36m(CriticModelRayActor pid=4272)[0m     "prescale_gradients": false, 
[36m(CriticModelRayActor pid=4272)[0m     "wall_clock_breakdown": false, 
[36m(CriticModelRayActor pid=4272)[0m     "data_types": {
[36m(CriticModelRayActor pid=4272)[0m         "grad_accum_dtype": "fp32"
[36m(CriticModelRayActor pid=4272)[0m     }, 
[36m(CriticModelRayActor pid=4272)[0m     "train_micro_batch_size_per_gpu": 2, 
[36m(CriticModelRayActor pid=4272)[0m     "train_batch_size": 128
[36m(CriticModelRayActor pid=4272)[0m }
[36m(ActorModelRayActorBOX pid=3672)[0m wandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc
[36m(CriticModelRayActor pid=4761)[0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.[32m [repeated 3x across cluster][0m
[36m(CriticModelRayActor pid=4272)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(CriticModelRayActor pid=4761)[0m 
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s][32m [repeated 3x across cluster][0m
[36m(CriticModelRayActor pid=4761)[0m 
Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  3.81it/s][32m [repeated 3x across cluster][0m
[36m(CriticModelRayActor pid=4761)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.15it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.09it/s][32m [repeated 3x across cluster][0m
[36m(CriticModelRayActor pid=4761)[0m Some weights of CriticModel were not initialized from the model checkpoint at /workspace/hdfs/model_hub and are newly initialized: ['value_head.weight'][32m [repeated 3x across cluster][0m
[36m(CriticModelRayActor pid=4761)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 3x across cluster][0m
[36m(CriticModelRayActor pid=4761)[0m Using /root/.cache/torch_extensions/py310_cu125 as PyTorch extensions root...[32m [repeated 3x across cluster][0m
[36m(CriticModelRayActor pid=4761)[0m Loading extension module cpu_adam...[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3672)[0m wandb: Currently logged in as: sikaili (sikaili-university-of-pennsylvania) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(ActorModelRayActorBOX pid=3672)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(ActorModelRayActorBOX pid=3672)[0m wandb: Tracking run with wandb version 0.19.6
[36m(ActorModelRayActorBOX pid=3672)[0m wandb: Run data is saved locally in /workspace/simpleRL-swebench/train/wandb/run-20250212_093531-8e58gw5a
[36m(ActorModelRayActorBOX pid=3672)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(ActorModelRayActorBOX pid=3672)[0m wandb: Syncing run swebench_ppo
[36m(ActorModelRayActorBOX pid=3672)[0m wandb: â­ï¸ View project at https://wandb.ai/sikaili-university-of-pennsylvania/openrlhf_train_ppo
[36m(ActorModelRayActorBOX pid=3672)[0m wandb: ğŸš€ View run at https://wandb.ai/sikaili-university-of-pennsylvania/openrlhf_train_ppo/runs/8e58gw5a
[36m(ActorModelRayActorBOX pid=3672)[0m =========================== Finish defining metrics ===========================
[36m(ActorModelRayActorBOX pid=3672)[0m ====================== Finish configuring Trainer ======================
[36m(ActorModelRayActorBOX pid=3672)[0m ====================== Start fitting ======================
[36m(ActorModelRayActorBOX pid=3672)[0m ====================== Start making experience ======================
[36m(ActorModelRayActorBOX pid=3672)[0m **************** RemoteExperienceMakerBOX.make_experience_list ****************
[36m(ActorModelRayActorBOX pid=3672)[0m 
Episode [1/20]:   0%|          | 0/25 [00:00<?, ?it/s]
[36m(ActorModelRayActorBOX pid=3797)[0m /usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:638: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.
[36m(ActorModelRayActorBOX pid=3797)[0m   warnings.warn(
Traceback (most recent call last):
  File "/workspace/simpleRL-swebench/train/openrlhf/cli/train_ppo_ray_box.py", line 407, in <module>
    train(args)
  File "/workspace/simpleRL-swebench/train/openrlhf/cli/train_ppo_ray_box.py", line 186, in train
    ray.get(refs)
  File "/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py", line 2623, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py", line 861, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(OutOfMemoryError): [36mray::ActorModelRayActorBOX.fit()[39m (pid=3672, ip=0.0.0.0, actor_id=ac2989f285965792a5c42d7702000000, repr=<openrlhf.trainer.ray.ppo_actor.ActorModelRayActorBOX object at 0x7f3eeb17e5f0>)
  File "/workspace/simpleRL-swebench/train/openrlhf/trainer/ray/ppo_actor.py", line 874, in fit
    trainer.fit(
  File "/workspace/simpleRL-swebench/train/openrlhf/trainer/ppo_trainer_prm800k_box.py", line 237, in fit
    self.experience_maker.make_experience_list(rand_prompts, rand_answer, **self.generate_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/workspace/simpleRL-swebench/train/openrlhf/trainer/ppo_utils/experience_maker.py", line 3722, in make_experience_list
    experiences = super().make_experience_list(all_prompts, all_answers, **generate_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/workspace/simpleRL-swebench/train/openrlhf/trainer/ppo_utils/experience_maker.py", line 3000, in make_experience_list
    self.generate_samples(all_prompts, all_answers, **generate_kwargs),
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/workspace/simpleRL-swebench/train/openrlhf/trainer/ppo_utils/experience_maker.py", line 3740, in generate_samples
    return super().generate_samples(all_prompts, all_answers, **generate_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/workspace/simpleRL-swebench/train/openrlhf/trainer/ppo_utils/experience_maker.py", line 3082, in generate_samples
    sequences, attention_mask, action_mask = self.actor.generate(**inputs, **generate_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/workspace/simpleRL-swebench/train/openrlhf/models/actor.py", line 139, in generate
    sequences = self.model.generate(**generate_args)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 2215, in generate
    result = self._sample(
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 3206, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1552, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1561, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 1164, in forward
    outputs = self.model(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1552, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1561, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 895, in forward
    layer_outputs = decoder_layer(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1552, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1561, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 638, in forward
    hidden_states = self.mlp(hidden_states)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1552, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1561, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
    return self.down_proj(self.act_fn(self.gate_proj(hidden_state)) * self.up_proj(hidden_state))
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1552, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1561, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py", line 404, in forward
    return F.silu(input, inplace=self.inplace)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 2105, in silu
    return torch._C._nn.silu(input)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.70 GiB. GPU 0 has a total capacity of 47.43 GiB of which 2.17 GiB is free. Process 27520 has 30.32 GiB memory in use. Process 27648 has 14.89 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[36m(ActorModelRayActorBOX pid=3672)[0m 
Episode [1/20]:   0%|          | 0/25 [00:02<?, ?it/s]
[36m(ActorModelRayActorBOX pid=3797)[0m ====================== Finish configuring Trainer ======================[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3797)[0m ====================== Start fitting ======================[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3797)[0m ====================== Start making experience ======================[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3797)[0m **************** RemoteExperienceMakerBOX.make_experience_list ****************[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3672)[0m /usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:638: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3672)[0m   warnings.warn([32m [repeated 3x across cluster][0m
2025-02-12 09:35:40,796	ERR cli.py:68 -- [31m---------------------------------------[39m
2025-02-12 09:35:40,796	ERR cli.py:69 -- [31mJob 'raysubmit_6tGve3tEijPu73PT' failed[39m
2025-02-12 09:35:40,796	ERR cli.py:70 -- [31m---------------------------------------[39m
2025-02-12 09:35:40,796	INFO cli.py:83 -- Status message: Job entrypoint command failed with exit code 1, last available logs (truncated to 20,000 chars):
    return torch._C._nn.silu(input)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.70 GiB. GPU 0 has a total capacity of 47.43 GiB of which 2.17 GiB is free. Process 27520 has 30.32 GiB memory in use. Process 27648 has 14.89 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[36m(ActorModelRayActorBOX pid=3672)[0m 
Episode [1/20]:   0%|          | 0/25 [00:02<?, ?it/s]
[36m(ActorModelRayActorBOX pid=3797)[0m ====================== Finish configuring Trainer ======================[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3797)[0m ====================== Start fitting ======================[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3797)[0m ====================== Start making experience ======================[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3797)[0m **************** RemoteExperienceMakerBOX.make_experience_list ****************[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3672)[0m /usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:638: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActorBOX pid=3672)[0m   warnings.warn([32m [repeated 3x across cluster][0m

